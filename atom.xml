<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://zy080080.github.io/</id>
    <title>听故事的人</title>
    <updated>2021-01-18T23:13:04.304Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://zy080080.github.io/"/>
    <link rel="self" href="https://zy080080.github.io/atom.xml"/>
    <subtitle>天青色等烟雨，而我在等你</subtitle>
    <logo>https://zy080080.github.io/images/avatar.png</logo>
    <icon>https://zy080080.github.io/favicon.ico</icon>
    <rights>All rights reserved 2021, 听故事的人</rights>
    <entry>
        <title type="html"><![CDATA[OS：主記憶管理ーページ置き換え方式]]></title>
        <id>https://zy080080.github.io/post/XhbY1TXpf/</id>
        <link href="https://zy080080.github.io/post/XhbY1TXpf/">
        </link>
        <updated>2021-01-19T00:02:07.000Z</updated>
        <summary type="html"><![CDATA[<p>教科書第12章　まとめ</p>
]]></summary>
        <content type="html"><![CDATA[<p>教科書第12章　まとめ</p>
<!-- more -->
<p>静的ページ置き換え方式</p>
<ul>
<li>LRU(Least Recently Used)</li>
<li>LFU(Least Frequently Used)</li>
<li>FIFO(First In First Out)</li>
</ul>
<p><strong>Beladyの例外</strong>：</p>
<ul>
<li>ページフレーム数を増やした時，ページフォルトが増加してしまう現象</li>
<li>原因
<ul>
<li>ページフレーム数により置き換えパターンが変化してしまうアルゴリズム　例）FIFO</li>
</ul>
</li>
</ul>
<p><strong>ワーキングセット方の近似</strong>：</p>
<ul>
<li>ワーキングセットの大きさ＝プロセスに割り当てるページ数
<ul>
<li>ワーキングセットを調べるのはコスト膨大</li>
<li>何らかの方法で近似</li>
</ul>
</li>
<li>ページフォルト発生の平均間隔
<ul>
<li>大きい場合（頻度小）
<ul>
<li>プロセスに与えられているページフレームは比較的十分</li>
</ul>
</li>
<li>小さい場合（頻度大）
<ul>
<li>プロセスには十分なページフレームが与えられていない</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>ページフォルト平均間隔＋LRU</strong>：</p>
<ul>
<li>ワーキングセット方の近似とLRUの組み合わせ</li>
<li>プロセスに割り当てるページフレーム数を<strong>動的</strong>に変更</li>
<li>アルゴリズム
<ul>
<li>ページフォルトの平均間隔を計算</li>
<li>平均間隔がある値より小さい場合
<ul>
<li>プロセスに与えるページフレーム数を増やす</li>
</ul>
</li>
<li>平均間隔がある値より大きい場合
<ul>
<li>プロセスに与えるページフレーム数を減らす</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<p>1.ページ置き換え方式として，プロセスの生成時にプロセスに与えるページ数を決定する<strong>静的ページ置き換え方式</strong>と，プロセスの実行中にプロセスに与えるページ数が変化する<strong>動的ページ置き換え方式</strong>がある。</p>
<p>2.ページ置き換えアルゴリズムとして，<strong>最長不使用ページ置き換え（LRU）アルゴリズム</strong>，<strong>最低使用頻度順ページ置き換え（LFU）アルゴリズム</strong>，<strong>到着順ページ置き換え（FIFO）アルゴリズム</strong>などがある。</p>
<p>3.プロセスに与えるページ数を増やした結果，ページフォルト回数が増加してしまうBeladyの例外という現象がある。このような性質を持たないページ置き換えアルゴリズムを<strong>スタックアルゴリズム</strong>と呼ぶ。</p>
<p>4.動的ページ置き換えにおいて，プロセスに与えるページ数を決める手法として，プロセスが直近にアクセスしたページ集合（ワーキングセット）の大きさに応じて決定する<strong>ワーキングセット法</strong>がある。</p>
<p>5.ワーキングセットを下回るメモリ量しかプロセスが確保できない場合，常時ページフォルトが発生し，CPUの実効効率を低下させる<strong>スラッシング</strong>が発生する。</p>
<p>12.2)ワーキングセットを求めるのは事実上不能な理由を示すとともに、動的ページ置き換えにおけるページフォールト平均間隔＋LRU法について、ワーキングセットを求めずにどのように実現したかを中心に説明しなさい。<br>
ワーキングセットは常時に命令フェッチ、デコード、命令実効のサイクルで変わるため，求めるのは事実上不可能である。そこで，ワーキングセット法を近似するために，ページフォルト発生の平均間隔を計算し，この情報を静的置換えアルゴリズムに加えて，動的にプロセスに与えるページフレーム数を変えるのは，ページフォルト平均間隔+LRU法である。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[OS：主記憶管理ー仮想記憶]]></title>
        <id>https://zy080080.github.io/post/D3L-F6vjm/</id>
        <link href="https://zy080080.github.io/post/D3L-F6vjm/">
        </link>
        <updated>2021-01-18T16:06:45.000Z</updated>
        <summary type="html"><![CDATA[<p>教科書第11章　まとめ</p>
]]></summary>
        <content type="html"><![CDATA[<p>教科書第11章　まとめ</p>
<!-- more -->
<p>仮想記憶</p>
<ul>
<li>大きさが無限の仮想アドレスを提供</li>
<li>ただし，スワップ操作に膨大な時間を要する</li>
</ul>
<p><strong>デマンドページング</strong>：</p>
<ul>
<li>ページフォルトが発生した時点</li>
<li>必要になった際に必要なページをスワップイン</li>
<li>スワップインの前にページフォルトが必ず発生</li>
<li><strong>ページフォルト処理にかかるコスト</strong>を削減したい</li>
</ul>
<p><strong>プリページング</strong>（予測ページング）</p>
<ul>
<li>必要になりそうなページを前もってスワップイン</li>
<li>予測が当たればページフォルトは発生せず<strong>コスト削減</strong></li>
</ul>
<p>デマンドプリフェッチ：</p>
<ul>
<li>ページフォルト割り込みが発生したタイミングで
<ul>
<li>ページフォルトを起こした対象ページは無論スワップイン</li>
<li><strong>将来必要と予想される数ページを同時に</strong>スワップイン</li>
</ul>
</li>
</ul>
<hr>
<p>1.仮想記憶の性能を向上させるためには，できる限りスワップ操作を行わないことが重要である。したがって，ページフォルト時にどのページをスワップアウトするかを決定するスワップスケジューリングは重要である。</p>
<p>2.スワップ操作は最小限にするべきであり，あらかじめ必要とされるページを事前にスワップインする方式として，<strong>デマンドプリフェッチ</strong>，<strong>初期ロードプリフェッチ</strong>などがある。</p>
<p>3.もっともアクセスされていないページをスワップアウトの対象とする<strong>LRUアルゴリズム</strong>は，今後アクセスされる確率のもっとも少ないページを近似的に選択可能なアルゴリズムである。しかし，このLEUアルゴリズムを正確に実装することも困難であり，経験的手法による近似的な実装が必要となる。</p>
<p>4.LRUアルゴリズムを近似的に実装するために，ページテーブル内に前回のページフォルト以降，当該ページの参照の有無を示す参照ビットを追加する。次のページフォルト時点で，参照頻度表を更新することにより，近似的，かつ少ない不可でLRUアルゴリズムを実装することが可能となる。</p>
<p>5.プログラムのアクセスする主記憶領域には，時間的および空間的局所性がある。さらに，プログラムが関数や手続きを高級言語で記述した場合は，関数や手続きの呼び出し時点で，急激にアクセスするページが変化する<strong>フェーズ現象</strong>が発生する。</p>
<p>(11-1)正確なLRUはなぜ実装困難なのかを、具体的な操作、および数字を示して説明しなさい。<br>
LRUを実現するには，ページテーブルに，各ページのアクセス時刻を記録する項目を追加する必要がある。具体的には，主記憶アクセスごとに時刻を調べてアクセス時刻を更新し，ページフォルト時にページテーブルを走査して，最もアクセス時刻の古い項目を探す必要がある。<br>
しかし，主記憶アクセスは10の-9乗秒程度の速度を要求され，時刻を更新するのに10の-9乗秒でできないため，LRUは実装困難である。</p>
<p>(11-2)高級言語によるプログラムの主記憶アクセスパターンのフェーズ化が、どのような時点で、なぜ起こるかを、２つ事例を示して、説明しなさい。<br>
フェーズ化は，プログラムがアクセスするページは主記憶上隣接した領域を連続してアクセスする時，及びある時刻を境にプログラムがアクセスするページが急に切り替わる時に起こる。<br>
事例：1.ループを抜けた時。2.実行する関数が変わった時。<br>
その理由は，プログラムが頻繁にアクセスするページ，またはその近くのアドレスに再びアクセスしなくなるからである。</p>
<p>(11-3)スワップインすべき場所の選択に意味がないことを示しなさい。<br>
ページシステムの特徴に，ページテーブルを介して，ページとページフレームをマッピンッグすることによるページフレームの動的再配置機能がある。よって，スワップイン操作により，該当ページが主記憶上のどのページフレームに読み込まれてもシステムの性能やプロフラム側が発行するアドレスに全く影響しない。<br>
　通常のメモリアクセスは10<sup>(-9)秒程度の速度を要求されるが，スワップ操作時は10</sup>(-1)秒程度の時間を要求されるだけである。したがった，スワップ操作時にさらに10<sup>(-3)〜10</sup>(-2)秒程度の追加の処理を挿入しても，ほとんどシステム全体の性能に影響することはない。</p>
<p>ページングによるメモリ管理は，アドレスの上位を（ページ番号），下位を（オフセット）に分けて管理する方式である。（ページ番号）は（ページテーブル）内の位置を示し，示された（ページテーブル）のエントリーには各種フラグと（ページフレーム番号）を示すポインタが格納されている。仮想記憶におけるページ置き換えをページフォルト時に行う方式を（デマンドページング）と呼ぶ。さらに，ページフォルトが起こった時に，そのページだけではなく，将来必要となるページも呼び込む方式が（<strong>デマンドプリフェッチ</strong>）である。理想的なページ置き換えは，次にアクセスされる確率のもっとも（低い）ページを置き換え（スワップアウトする）方法である。この近似解として（LRU）がある。しかし，（LRU）も正確に実装することが困難なので，さらに近似が必要となる。<br>
　プログラムが使用するページの集合は，プログラムの実行にしたがって急激に変化することが多い，これを（フェーズ化）現象と呼び，一般に関数などにより，プログラムを（<strong>構造化</strong>）した場合に顕著となる</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[OS：主記憶管理ーセグメンテーション，ページかセグメンテーション]]></title>
        <id>https://zy080080.github.io/post/zAjTn6PkI/</id>
        <link href="https://zy080080.github.io/post/zAjTn6PkI/">
        </link>
        <updated>2021-01-18T11:35:35.000Z</updated>
        <summary type="html"><![CDATA[<p>教科書第10章　まとめ</p>
]]></summary>
        <content type="html"><![CDATA[<p>教科書第10章　まとめ</p>
<!-- more -->
<p><strong>多重レベルページング</strong>：</p>
<ul>
<li>従来のページングにおける，仮想アドレスの「ページ番号部」を複数に分割</li>
<li>それぞれをページ番号として階層化したテーブルを検索</li>
<li>必要なテーブルのみを主記憶上に置くことで，主記憶使用量を削減（残りは仮想記憶へ）</li>
<li>ただし，多段化により，主記憶アクセスは増加 =&gt;TLBにより解決</li>
</ul>
<p><strong>0レベルページング（連想写像方式）</strong>：</p>
<ul>
<li>一般的なページング
<ul>
<li>主記憶上にページテーブル</li>
<li>CPU内のMMUが，ページテーブルを用いてアドレス変換</li>
</ul>
</li>
<li>0レベルページング
<ul>
<li>ハードウェアとしてのMMUを持たない</li>
<li>一般的なページテーブルを持たず，連想メモリで構成したTLBでアドレス変換</li>
</ul>
</li>
<li>メリット
<ul>
<li><strong>高クロック</strong>実装が可能
<ul>
<li>MMU不要のため，CPU機構が単純化</li>
</ul>
</li>
</ul>
</li>
<li>デメリット
<ul>
<li>TLBヒットしなかった場合のオーバーヘッドが膨大
<ul>
<li>ソフトウェア処理のため</li>
</ul>
</li>
</ul>
</li>
<li>よって
<ul>
<li>主記憶使用量の少ないプログラムには<strong>高速</strong></li>
<li>主記憶使用量の多いプログラムには<strong>非常に低速</strong></li>
</ul>
</li>
</ul>
<p><strong>セグメンテーション</strong>：</p>
<p>ページングの上，プログラム部，データ部，スタック部などの分離とプロセス間で共有を実現する。</p>
<ul>
<li>ページ（ページング）
<ul>
<li>一定の大きさを割り当て単位とする</li>
</ul>
</li>
<li>セグメント（セグメンテーション）
<ul>
<li>プロセスに対し<strong>複数</strong>のセグメントを割り当て
<ul>
<li>各セグメントは論理的に<strong>独立</strong></li>
<li>プログラム部，データ部など固有領域として使用可能</li>
</ul>
</li>
<li>各セグメントはその論理区間の大きさを自由に<strong>増減可能</strong></li>
</ul>
</li>
<li>利点
<ul>
<li>プログラム部，データ部など，用途別に複数をプロセスに割り当て</li>
<li>各セグメンテーションは大きさを増減可能</li>
</ul>
</li>
<li>欠点
<ul>
<li>フラグメンテーション</li>
</ul>
</li>
</ul>
<p><strong>ページ化セグメンテーション</strong>：</p>
<ul>
<li>セグメンテーションを複数のページにより構成する。</li>
<li>セグメントごとにページテーブルを用意</li>
<li>利点：
<ul>
<li>フラグメンテーションの回避
<ul>
<li>主記憶割り当ては基本的にページ単位</li>
</ul>
</li>
<li>複数セグメント
<ul>
<li>各セグメントは大きさ増減可能</li>
<li>複数使用により，用途別に使い分け可能</li>
</ul>
</li>
<li>プロセス間共有
<ul>
<li>セグメンテーションとほぼ同様に共有可能<br>
　- ページテーブルの分散</li>
<li>ページテーブルが複数に分割されるので，多重レベルページング同様，その一部を<strong>仮想記憶に追い出すことで主記憶使用量削減</strong></li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h2 id="ポイント">ポイント</h2>
<p>1.高級言語では，プログラム領域，データ領域，スタック領域，動的データ領域など複数のアドレス空間を用いる。<strong>セグメンテーション</strong>を用いることにより，プログラムに対して複数の異なるアドレス空間を提供することが可能である。さらに，複数のプロセス間で仮想アドレス空間を共有する共有メモリも容易に実現可能である。</p>
<p>2.<strong>ページカセングメンテーション</strong>は，ページングとセグメンテーションの両方の利点を有する方式であり，現在の主記憶管理手法の主流である。</p>
<p>3.ページングシステムでは，ページテーブルの大きさが大きくなり，主記憶領域を圧迫する。しかし，<strong>ページかセグメンテーション</strong>や<strong>多重レベルページング</strong>などでは，ページテーブルも仮想記憶内で管理するため，解決可能である。</p>
<p>4.最小限のハードウェアで高性能を得るために開発され，MIPS社のR2000で採用された0レベルページングは，ページテーブルの管理を，ハードウェアで実装されたMMUではなく，ソフトウェア割り込みで実装した。</p>
<p>10.1　多重レベルページングと仮想記憶を用いることにより，主記憶内に存在するページテーブルの大きさが無視できることを示せ。<br>
　多重レベルページングを用いることにより，各プロセスが必要とするページテーブル自体も仮想記憶の対象となる。つまり，全てのページテーブルのうち，直近にアクセスされたページテーブルの一部のみが主記憶に存在することになる。したがって，プロセスが現時点で必要としているページテーブル部分のみが主記憶に配置される。</p>
<p>10.2　ページ化セグメンテーションにおいて，外部・内部フラグメンテーションの問題について説明せよ。<br>
　ページ化セグメンテーションは主記憶の割り当てはページ単位の固定長割り当てなので，外部セグメンテーションは存在しない。しかし，プロセスには主記憶をページ単位で割り当てるため，例えばページサイズが8kBの場合，複数割り当てたページ群の最後のページで平均4KBの未使用領域（内部フラグメンテーション）が発生する。しかし，現在のプロセスに必要な主記憶量に比べると無視できる量である。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[OS：主記憶管理ーページング]]></title>
        <id>https://zy080080.github.io/post/M7ToAnBlI/</id>
        <link href="https://zy080080.github.io/post/M7ToAnBlI/">
        </link>
        <updated>2021-01-18T06:23:01.000Z</updated>
        <summary type="html"><![CDATA[<p>教科書第9章　まとめ</p>
]]></summary>
        <content type="html"><![CDATA[<p>教科書第9章　まとめ</p>
<!-- more -->
<p><strong>仮想記憶</strong>：主記憶の動的再配置により，プロセスが使用できる主記憶領域を無限大にする方式。</p>
<p><strong>仮想アドレス</strong>：記憶容量に制限のない論理アドレス。</p>
<p><strong>スワップイン</strong>：</p>
<ul>
<li>実行中のプログラムが必要となる領域を二次記憶から主記憶に転送する操作。</li>
</ul>
<p><strong>スワップアウト</strong>：</p>
<ul>
<li>スワップインを行う際，その空き領域を確保するために，当面必要としない領域を主記憶から二次記憶に転送する操作。</li>
</ul>
<p>記憶領域の仮想化</p>
<ul>
<li>仮想アドレス空間の一部が物理メモリに存在</li>
<li>仮想アドレスと物理アドレスの対応付けが必要</li>
<li>物理メモリ上に存在する「仮想記憶の一部」は時々刻々変化する（<strong>動的再配置</strong>）</li>
<li>対応付けも時々刻々へ変化</li>
</ul>
<p><strong>ページング</strong>：ロック/キー機構に動的再配置機能を加えた方式である。</p>
<p><strong>ページ</strong>：<strong>仮想アドレス</strong>を上位部と下位部に分割することによって生成されたブロック単位。</p>
<p><strong>ページフレーム</strong>：<strong>物理アドレス</strong>を上位部と下位部に分割することによって生成されたブロック単位。</p>
<p><strong>ページテーブル</strong>：ページ番号からページフレーム番号へのマッピングを行うテーブル。</p>
<p>仮想アドレスは通常プロセスごとに独立して存在する多重仮想記憶として実装される。したがって，ページテーブルもプロセスごとに複数必要となり，書くプロセスのPSW情報中に，主記憶中のどこに自プロセスのページテーブルが格納されているかを示すポインタ情報を格納する<strong>ページテーブルレジスタ</strong>がある。</p>
<p>フラグ</p>
<ul>
<li><strong>Vフラグ</strong>（Virtual Memory Flag）
<ul>
<li>そのページが主記憶に存在するか否かを示す</li>
<li>1の場合はスワップインが必要</li>
</ul>
</li>
<li><strong>Pフラグ</strong>（Permission Flag）
<ul>
<li>そのページに対するアクセス条件を表す</li>
<li>例：001（読み込み可）010（書き込み可）100（実行可）</li>
</ul>
</li>
<li><strong>Cフラグ</strong>（Change Flag）
<ul>
<li>スワップイン後，そのフレームに対して書き込みが行われたか（変更されたか）否かを表す</li>
<li>1の場合は，スワップアウト時に二次記憶へのフレームの書き戻しが必要</li>
</ul>
</li>
</ul>
<p>プロセスはページ単位でしかメモリ量を要求でいないため，メモリフラグメンテーションの問題は発生しない。<br>
<strong>内部フラグメンテーション</strong>：割り当てられたが，使用されない領域。</p>
<ul>
<li>一ページが4~8kB程度なので，主記憶の全容量からすると微々たる大きさ，ほとんど無視できる。</li>
</ul>
<p><strong>ページングの問題点</strong>：</p>
<ul>
<li>ページテーブルの巨大さ
<ul>
<li>例）仮想アドレス32bit，1ページ8kBの場合
<ul>
<li>ページエントリ数：50万</li>
</ul>
</li>
<li>ページテーブルはプロセス毎に独立
<ul>
<li>例）100プロセスの場合のエントリ数：5000万，1エントリ10Bで構成すると500MB</li>
</ul>
</li>
<li>解決法：
<ul>
<li>ハッシュ関数によるページテーブル</li>
</ul>
</li>
</ul>
</li>
<li>メモリアクセスの増大
<ul>
<li>ページテーブルは主記憶内に存在</li>
<li>1回で２度の主記憶アクセスが必要
<ul>
<li>ページテーブルへのアクセス</li>
<li>物理アドレスへのアクセス</li>
</ul>
</li>
<li>解決法：
<ul>
<li>連想レジスタ方式</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>連想レジスタ</strong>（TLB：Translation Lookaside Buffer）：</p>
<ul>
<li>最近行われた変換結果をCPU内で保持</li>
<li>小容量で高速</li>
<li>一般的にプログラムは，「<strong>一度アクセスしたアドレスを近いうちに再度アクセスする可能性が高い</strong>」ことを利用</li>
</ul>
<p>アクセス速度の違い</p>
<ul>
<li>CPU基本サイクル   約10^(-9)秒</li>
<li>CPUが主記憶へアクセスする速度 約10^(-7)秒</li>
<li>スワップイン・スワップアウトで二次記憶へアクセス速度  約10^(-3)秒</li>
</ul>
<hr>
<p>1.主記憶の再配置機能を持つ<strong>ページング</strong>は，現在用いられている主記憶管理の基本である。仮想アドレスの上位をページ番号部，下部をオフセット部とし，ページ番号部は，ページテーブルを参照して，物理アドレスであるページフレーム番号に変換される。また，ページテーブルには各ページごとにアクセス制御グラフなどが配置され，ページのアクセス権を設定することができる。</p>
<p>2.ページングは，仮想記憶が実現できるとともに，メモリフラグメンテーション問題も解決可能である。しかし，ページテーブルを主記憶に配置する必要があるため，主記憶へのアクセス速度が低下する可能性がある。アクセス速度を低下させないために，<strong>TLB</strong>（<strong>連想レジスタ</strong>）を用いる。</p>
<p>3.ページテーブルを主記憶上に全て配置した場合，その大きさが無視できなくなる。主記憶上のページテーブルを削減するとして，ハッシュ関数を用いて，現在主記憶上にあるページフレームを管理するページテーブルのみを主記憶上に配置する方式がある。</p>
<p>4.仮想記憶の利用を前提とした場合，主記憶のアクセス速度と，２次記憶のアクセス速度に注意する必要がある。両者のアクセス速度は数万倍の差があり，過度な仮想記憶の利用はできる限り避けるべき。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[OS：主記憶管理ー主記憶割り当て]]></title>
        <id>https://zy080080.github.io/post/ES4qIO3DM/</id>
        <link href="https://zy080080.github.io/post/ES4qIO3DM/">
        </link>
        <updated>2021-01-17T15:41:41.000Z</updated>
        <summary type="html"><![CDATA[<p>教科書第8章　まとめ</p>
]]></summary>
        <content type="html"><![CDATA[<p>教科書第8章　まとめ</p>
<!-- more -->
<p>領域要求のタイミング：</p>
<ul>
<li>静的（static）要求
<ul>
<li>プログラム実行開始時に必要領域を要求</li>
</ul>
</li>
<li>動的（dynamic）要求
<ul>
<li>プログラム実行開始時に最低限の領域を要求</li>
<li>実行につれてさらに必要となった場合はその都度要求</li>
</ul>
</li>
</ul>
<p><strong>固定区画方式</strong>：</p>
<ul>
<li>プロセスに割り当てる領域の大きさをあらかじめ決めておく</li>
<li>プロセスから要求があった際，その決められた大きさの領域を割り当てる</li>
<li>特徴：
<ul>
<li>新しいプロセスの生成時に，領域を割り当てるコストが非常に少ない（選択の幅がない）</li>
</ul>
</li>
<li>欠点：
<ul>
<li>小規模の主記憶領域しか必要としないプロセスにとっては，利用しない領域まで割り当ての対象となり，結果としてOS全体で考えた場合の主記憶領域の使用効率が低下する。</li>
</ul>
</li>
</ul>
<p><strong>可変区画方式</strong>：</p>
<ul>
<li>プロセスは，必要な分だけ領域を要求</li>
<li>プロセスごとに要求サイズは異なる</li>
<li>要求があった分だけ割り当てる</li>
<li>問題点
<ul>
<li>空き領域の検索コスト
<ul>
<li>処理が進行するに従い，様々な大きさの空き領域が発生</li>
<li>新しいプロセスの要求に合う大きさの空き領域を探すコストが増大</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>断片化（フラグメンテーション）</strong>：</p>
<ul>
<li>プロセスからの要求サイズは異なるため，可変区画方式で眼持ちを割り当てると，プロセスが使えない大量の小さな領域が残ってしまう現象。</li>
<li>解決法：<strong>メモリコンパクション</strong>
<ul>
<li>メモリを確保しているプロセスの実行を止めた後に，断片化した領域を１つの連続した領域にまとめる。</li>
</ul>
</li>
</ul>
<p>可変区画方式における空き領域管理：</p>
<ul>
<li><strong>ベストフィット方式</strong>
<ul>
<li>割り当てた残り領域がもっとも少なくなる空き領域に割り当てる方式</li>
<li>一番効率的に見えるが</li>
<li>欠点
<ul>
<li>空き容量の探索コストが大きくなる場合がある</li>
<li>残った領域が小さすぎて他のプロセスが使用できない確率が高い</li>
</ul>
</li>
</ul>
</li>
<li><strong>ワーストフィット方式</strong>
<ul>
<li>割り当てた残り領域がもっとも大きくなる空き領域に割り当てる方式</li>
<li>残った領域は，ベストフィット方式より比較的大きくなる</li>
<li>欠点
<ul>
<li>処理が進むにつれ空き領域の大きさが均一化し，大きい要求に応じられない</li>
</ul>
</li>
</ul>
</li>
<li><strong>ファーストフィット方式</strong>
<ul>
<li>要求された量を確保できる最初に見つかった領域を割り当てる方式</li>
<li>探索コストが小さい。主記憶領域の全てを調べる必要がない</li>
<li>アドレス上位に大きい領域が残りやすくなり，大きい要求にも対応しやすい</li>
</ul>
</li>
</ul>
<h2 id="領域管理">領域管理</h2>
<h3 id="リスト方式">リスト方式</h3>
<table>
<thead>
<tr>
<th style="text-align:center">アドレス：A1</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">サイズ：S1</td>
</tr>
<tr>
<td style="text-align:center">next</td>
</tr>
</tbody>
</table>
<p>アドレス順リストの場合：ファーストフィット方式での検索が高速。<br>
大きさ順リストの場合：ベストフィット方式での検索が高速。</p>
<h3 id="ビットマップ方式">ビットマップ方式</h3>
<p>空き情報を示す配列</p>
<ul>
<li>ビットマップ
<ul>
<li>記憶領域を単位ブロックに分割
<ul>
<li>例：アドレスの上位数ビットが共通の部分など</li>
</ul>
</li>
<li>各領域に対応するビットを用意</li>
</ul>
</li>
<li>ビット配列により，主記憶全体の空き領域を表現
<ul>
<li>大きい連続した空き領域を検索する際は
<ul>
<li>フラグに０が続いている部分を探索</li>
</ul>
</li>
<li>各要素へのアクセスは高速だが，<strong>空き領域の検索コストが大きくなりがち</strong></li>
</ul>
</li>
</ul>
<h2 id="プログラムのロードと領域の再配置">プログラムのロードと領域の再配置</h2>
<p>プログラム記述から実行までの流れ：<br>
通常はリンケージエディタにおいてユーザがプログラム中に使ったライブラリ関数を結合し，即時実行可能形式（<strong>ロードモジュール</strong>）として，ファイルに格納されるとともに，実行時にはこのイメージのまま主記憶にロードされる。</p>
<p><strong>静的ライブラリ</strong></p>
<ul>
<li>リンク時にロードモジュールに<strong>埋め込み</strong>（静的リンク）</li>
<li>複数プログラムで使用されるライブラリがある場合，主記憶領域の無駄</li>
</ul>
<p><strong>共有ライブラリ</strong>：</p>
<ul>
<li>主記憶内にロードされた複数のプログラムから共有可能なライブラリ。</li>
<li>リンカはロードモジュールにライブラリの埋め込みを行わない。</li>
<li>共有ライブラリに対するリンク情報のみロードモジュールに書き込む</li>
<li>ロードモジュールは<strong>リンク情報のみ</strong>を持ち，<strong>実行時にリンク</strong>（ダイナミックリンク）</li>
<li>複数プログラムで使用される場合でも，各ライブラリは１つのイメージだけ主記憶上に存在すればよい</li>
<li>主記憶領域（およびディスク領域）の有効活用</li>
<li>共有ライブラリが<strong>リエントラント</strong>である</li>
</ul>
<p><strong>リエントラント性</strong></p>
<ul>
<li>複数のプログラム間で同一関数を共有するには，あるプログラムがその関数を実行中に中断された後，他のプログラムが同一関数を実行した後であっても，中断直後の状態から同一関すを再開できる必要がある。</li>
<li>複数のプログラムが主記憶上にロードされた変数を同時に利用可能な性質を<strong>リエントラント性</strong>(再入可能性)と呼ぶ。</li>
<li>各呼び出しごとに，作業領域を保存する仕組みが必要
<ul>
<li>関数内でグローバル偏すをアクセスしない。関数内でstaticな変数を使わないなど。</li>
</ul>
</li>
</ul>
<p><strong>実行時結合</strong>：実行時にリンク操作を行う</p>
<p><strong>リロケータブル（再配置可能）</strong>：プログラム本体が，主記憶上の任意の位置に配置（ロード）されても実行可能である性質。</p>
<ul>
<li>この場合，プログラム内の全てのアドレス指定が，プログラムの先頭のアドレスからの相対位置で表現されている必要がある。</li>
</ul>
<p><strong>共有ライブラリの現状</strong></p>
<ul>
<li>共有ライブラリは，主記憶の効率的利用という観点からは望ましい</li>
<li>しかし，プログラム（ライブラリ）全てがリエントラント性を満たすためには相当な書き換えが必要。</li>
<li>現状
<ul>
<li>ダイナミックリンク（単体）は，利用されている
<ul>
<li>２次記憶の有効利用</li>
<li>脆弱性対応時の容易性 =&gt;ライブラリだけを配布すれば良い（例　Windows　DLL）</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="オーバーレイ">オーバーレイ</h2>
<p>オーバーレイ</p>
<ul>
<li>指定した時刻に，アプリケーションのどの部分が主記憶上に存在すべきかをプログラマが指定する仕組み</li>
<li>毎に実行されたコード（親関数など）のうち，さしあたり(目前)必要のなくなったコードがロードされている主記憶領域に対して，新しく必要となったコードを上書き（overlay）できる</li>
<li>欠点
<ul>
<li>非常に複雑でエラーを起こしやすい</li>
<li>プログラマの負担が増大</li>
</ul>
</li>
</ul>
<p>軽量に仮想記憶を実装できるオーバーレイはIoTなどの分野で今後も重要な位置を占める</p>
<hr>
<p>1.マルチプログラミング環境では，プログラムの発生，消滅が頻繁に起こるため，プログラム（およびデータ）を格納する領域を管理する方式が重要となる。</p>
<p>2.メモリの割り当て方式には，あらかじめ決められたシステムで決めた大きさの領域を全てのプロセスに平等に割り当てる<strong>固定区画方式</strong>と，プロセスが要求する大きさの領域を与える可変区画方式がある。</p>
<p>3.可変区画方式において，もし適切な管理を行わないと，プロセスが使えない断片的なメモリ領域が数多く発生する<strong>メモリフラグメンテーション</strong>が起こる。</p>
<p>4.空き領域を管理する方法として，リストデータ構造を用いるリスト方式と，配列を用いる<strong>ビットマップ方式</strong>がある。また，割り当て方式として，<strong>ベストフィット方式</strong>，<strong>ファーストフィット方式</strong>，<strong>ワーストフィット方式</strong>がある。</p>
<p>5.マルチプログラミング環境では，主記憶を効率よく利用するために，複数のプログラムが，主記憶中にロードされたライブラリを共有できる<strong>共有ライブラリ</strong>が有効な手法である。共有ライブラリを実現するためには，プログラムのリエントラント性，およびプログラムの実行時にライブラリを結合する<strong>ダイナミックリンク</strong>が必要である。</p>
<p>6.プログラマが明示的にプログラムの主記憶へのロードを管理し，現在実行している部分のみを主記憶にロードすることにより，プログラムの実行に必要な主記憶量を提言する方法を<strong>オーバーレイ</strong>と呼ぶ。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[OS：主記憶管理基礎]]></title>
        <id>https://zy080080.github.io/post/u3Uh6KrGp/</id>
        <link href="https://zy080080.github.io/post/u3Uh6KrGp/">
        </link>
        <updated>2021-01-17T09:24:20.000Z</updated>
        <summary type="html"><![CDATA[<p>教科書第7章　まとめ</p>
]]></summary>
        <content type="html"><![CDATA[<p>教科書第7章　まとめ</p>
<!-- more -->
<p><strong>物理アドレス空間</strong>：主記憶上の実アドレス空間。</p>
<p><strong>論理アドレス空間</strong>：プログラムからみた，各プロセスごとに独立した実アドレス空間に対応するアドレス空間。</p>
<p><strong>主記憶管理部</strong>(memory management unit：<strong>MMU</strong>)：各プロセスごとの論理アドレス空間を一次元アドレスで表現されている受寄屋上の物理アドレス空間へ変換（Mapping）を行うハードウェアである。</p>
<p><strong>ネーミング関数</strong>：</p>
<ul>
<li>変数，定数などの識別子を論理アドレスに変換する関数</li>
<li>コンパイル・リンク時に行われる</li>
</ul>
<p><strong>メモリ関数</strong>：</p>
<ul>
<li>論理アドレスから物理アドレスに変換する関数。</li>
<li>OSによって行われる</li>
</ul>
<p><strong>内容関数</strong>：</p>
<ul>
<li>物理アドレスから，そのアドレスに格納された内容に変換する関数</li>
<li>ハードウェアによって行われる</li>
</ul>
<p><strong>下限レジスタ</strong>：主記憶上のOS領域とユーザ領域の境界を示すレジスタである。</p>
<p>下限レジスタ機構とその問題点：</p>
<ul>
<li>ユーザ領域の下限を設定
<ul>
<li>下限レジスタが示す境界でOS/ユーザ領域を区別</li>
</ul>
</li>
<li>問題点
<ul>
<li>領域境界が１つしかない</li>
<li>OS領域を保護することしかできない</li>
<li>複数のプロセス間でアクセス権は設定できない</li>
</ul>
</li>
</ul>
<p>そのため，任意・複数の境界を設定し，プロセスごとにアクセス権を設定したい。 -&gt;ロック/キー機構</p>
<hr>
<p>1.<strong>主記憶管理</strong>の目的は，ユーザに独立した仮想アドレス空間を提供することである。理想的な仮想アドレス空間を持つべき特徴としては，大きさ無制限，プロセスごとに固有，プロセス間で主記憶空間を共有可，プログラム部，データ部，スタック部など複数の１次元アドレスがある。</p>
<p>2.<strong>下限レジスタ機構</strong>は，ユーザ領域とオペレーティングシステム領域を下限レジスタが示す位置で分離し，CPUの実行モードにより，オペレーティングシステム領域へのアクセスを制限する基本的な仕組みである。</p>
<p>3.<strong>ロック/キー機構</strong>は，アドレスを論理的に上位と下位に分け，上位部の内容を主記憶を示すアドレスとしてだけでなく，主記憶ブロックへのアクセス権が格納されているロックデータ配列への添字（ポインタ情報）として用いる。この考え方は，ページング，セグメンテーションによるメモリ管理の基礎である。<br>
　現在実行中のプロセスの主記憶に対するアクセス権がPSWに格納されていて，それをキー部に対応するロックデータと比較して，アクセスを許可するかどうかを決める。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[OS：並行プロセス-モニタ]]></title>
        <id>https://zy080080.github.io/post/ECsYYoE6u/</id>
        <link href="https://zy080080.github.io/post/ECsYYoE6u/">
        </link>
        <updated>2021-01-16T12:08:05.000Z</updated>
        <summary type="html"><![CDATA[<p>教科書第6章 まとめ</p>
]]></summary>
        <content type="html"><![CDATA[<p>教科書第6章 まとめ</p>
<!-- more -->
<p>モニタとセマフォ</p>
<table>
<thead>
<tr>
<th style="text-align:center">セマフォ</th>
<th style="text-align:center">モニタ</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">P命令</br>共有リソースの取得トライ。失敗時に待ち行列へ</td>
<td style="text-align:center">wait()</br>待ち行列へ</td>
</tr>
<tr>
<td style="text-align:center">V命令</br>共有リソース返却，待ちプロセスを１つ実行可能状態へ</td>
<td style="text-align:center">signal()（Javaではnotify()）</br>待ちプロセスを１つ実行可能状態へ</td>
</tr>
<tr>
<td style="text-align:center">-</td>
<td style="text-align:center">queue()</br>待ちプロセスの有無を返す</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:center">セマフォ</th>
<th style="text-align:center">モニタ</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">P命令を実行しないとセマフォの状態がわからない</td>
<td style="text-align:center">メソッドにより，共有リソースの状態を排他的に調べられる</td>
</tr>
<tr>
<td style="text-align:center">リソースを取ろうとしないと，空いているかどうか不明</td>
<td style="text-align:center">リソースの空きの確認とリソース待ちが分離</td>
</tr>
<tr>
<td style="text-align:center">取れなかったら，いきなり待ち行列に待たされる</td>
<td style="text-align:center">条件変数へのwaitにより，自由度の高い「待ち」が可能</td>
</tr>
</tbody>
</table>
<p><strong>モニタの利点（セマフォに対し）</strong>：</p>
<ul>
<li>リソース確認と「待ち」状態の分離
<ul>
<li>リソースに空きがない場合，「待ち」に入るかどうか自由に選べる</li>
</ul>
</li>
<li>排他制御すべきリソースの明示
<ul>
<li>モニタ内に記述されるため明示的</li>
<li>他の一般的な変数と判別しやすい</li>
<li>排他的メソッドを通じた処置により保護</li>
</ul>
</li>
<li>プログラマに安全で扱いやすい枠組みを提供</li>
</ul>
<hr>
<p>1.<strong>モニタ</strong>とは，オブジェクト思考の考え方を排他制御（およびプロセス同期）に適用した解法である。モニタ内には，排他制御の対象となる<strong>リソース</strong>，リソースを操作するための<strong>メソッド</strong>，オブジェクトの実体を生成する際に実行する<strong>初期コード</strong>，<strong>終了時コード</strong>が存在する。</p>
<p>2.モニタ内のリソースは，メソッドを介してのみアクセス可能である。また，各モニタのメソッドは排他的に実行される。したがって，プログラマはモニタ内のリソースの排他制御を考慮する必要はない。</p>
<p>3.モニタを用いることにより，セマフォよりもさらに抽象度が高くできるとともに，デッドロックの可能性のある処理を，コンパイラで実行前にある程度事前に検出することも可能となる。</p>
<p>複数のプロセスが，同時に実行されている場合，共通のリソース（共有変数など）にアクセスする場合は（排他制御）が必要となる。また，（排他制御）が必要となる領域のことを（クリティカルセクション）と呼ぶ。（排他制御）の解決方法の代表的な例は（セマフォ）である。これは，待ち行列と整数変数を持つデータ構造であり，（P）命令と（V）命令により制御する。一般的には，（クリティカルセクション）に入る前に（P）命令を，出る前に（V）命令を実行する。さらに，より抽象度の高い（排他制御）の方法として，（モニタ）がある。（モニタ）は，（排他制御）の対象となるリソースを（オブジェクト）指向の枠組みで抽象化したモデルである。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[OS：並列プロセス-セマフォ]]></title>
        <id>https://zy080080.github.io/post/oEPtkexau/</id>
        <link href="https://zy080080.github.io/post/oEPtkexau/">
        </link>
        <updated>2021-01-16T04:50:30.000Z</updated>
        <summary type="html"><![CDATA[<p>教科書第5章　まとめ</p>
]]></summary>
        <content type="html"><![CDATA[<p>教科書第5章　まとめ</p>
<!-- more -->
<p><strong>semaphore　セマフォ</strong>：整数型の変数（セマフォ変数）と，待ち行列からなるデータ構造を有する構造体である。この構造体へは，P命令，V命令の２つの操作が許されている。</p>
<p><strong>P命令</strong>：リソースを要求し，許可されない場合は待ち状態へ移行。</p>
<ul>
<li>空きリソースを1つ使用</li>
<li>空きリソース数（セマフォ変数）をデクリメント</li>
<li>空きがない場合，プロセスを待ち状態に</li>
</ul>
<p><strong>V命令</strong>：リソースを解放し，待ちプロセスを実行可能状態へ移行。待ちプロセスがない場合，空きリソース数をインクリメント。</p>
<ul>
<li>空きリソースを1つ解放</li>
<li>待ちプロセスを1つ実行可能状態に</li>
<li>待ちプロセスがない場合，空きリソース数（セマフォ変数）をインクリメント</li>
</ul>
<p><strong>デッドロック</strong>：全てのプロセスが，あるリソースを確保するために，別のリソースを確保したママ解放を待っている状態となってしまい，これらのリソースに関連する全てのプロセスの実行が止まってしまう状態。</p>
<p><strong>ダイニングフィロソファの解法</strong>：</p>
<ul>
<li>解法1：フォーク一本一本ではなく，「フォーク全体を使う権利」をセマフォで管理
<ul>
<li>うまくいくが，同時に一人しか食事できない。</li>
<li>実際は二人同時に食事可能な場合があるはず</li>
<li>リソースが有効利用できていない</li>
</ul>
</li>
<li>解法2：１つのプロセスだけが逆順でフォークを要求
<ul>
<li>うまくいくが，哲学者4が特殊であるため，<strong>公平性</strong>を欠いている可能性がある</li>
</ul>
</li>
<li>解法3：少し我慢をする哲学者
<ul>
<li>右のフォークを確保後，左のフォークが確保できなければ，一旦右のフォークを解放して少し待つ</li>
<li>これにより，「全員右フォークを確保した状態」から抜け出せる</li>
<li>問題点：全員が同時に「右フォーク確保，右フォーク解放」を繰り返すと，デッドロック。</li>
</ul>
</li>
<li>解法4：不定時間だけ我慢をする哲学者
<ul>
<li>右のフォークを確保後，左のフォークが確保できなければ，一旦右のフォークを解放して少し待つ</li>
<li>待つ時間はランダムに決定する</li>
<li>これによって，全員が同時に「右のフォークを確保，右のフォークを解放」を繰り返すことがなくなる</li>
<li>問題点：デッドロックが発生しないことを証明できない。フォークを解放して「譲った」哲学者は，次に優先される仕組みがないと公平性に欠ける。</li>
</ul>
</li>
<li>理想的な解法：
<ul>
<li>リソース確保に失敗した場合，当該リソースを確保するための<strong>待ち行列に並ぶことができる</strong>こと</li>
<li>全てのプロセスがリソースを<strong>平等に確保できる</strong>ことを保証すること</li>
</ul>
</li>
</ul>
<hr>
<p>1.<strong>P命令</strong>(wait)と<strong>V命令</strong>(signal)からなる<strong>セマフォア</strong>は，より抽象的な排他制御の仕組みとして開発された。セマフォを獲得できないプロセスは，待ち状態に移行するため，ビジーウェイティングの問題はない。</p>
<p>2.プロセス間通信や計算機間の通信(Local Area Network, Internetwork)をモデル化した<strong>プロデュサ/コンシューマ問題</strong>や，データベースアクセス制御をモデル化した<strong>リーダタイム問題</strong>は，非同期問題の解法として重要な例題である。</p>
<p>3.<strong>食事をする哲学者問題</strong>は，複数リソースを獲得する際のデッドロックをモデル化している。複数リソースを獲得するプログラムを作成する場合，常にデッドロックを考慮する必要がある。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[OS：並列プログラム-排他制御基礎]]></title>
        <id>https://zy080080.github.io/post/7nRN9HqLl/</id>
        <link href="https://zy080080.github.io/post/7nRN9HqLl/">
        </link>
        <updated>2021-01-16T02:33:25.000Z</updated>
        <summary type="html"><![CDATA[<p>教科書第4章　まとめ</p>
]]></summary>
        <content type="html"><![CDATA[<p>教科書第4章　まとめ</p>
<!-- more -->
<p><strong>プロセス協調</strong>：仕事の分担や通信など，複数プロセスが助け合う。</p>
<ul>
<li>プロセス間通信のための仕組み：通信バッファ
<ul>
<li>通信バッファがないと，送信側と受信側でタイミングを合わせる必要があり，受信側は，常にメッセージが来ないかをチェックしていなければならない。</li>
<li><strong>通信バッファの役割：通信バッファは，通信情報を一時的に保存する機能である。全てのプロセスからアクセスできる領域に存在し，送信側からみた場合，受信側プロセスの状態に関わらず，常時送信データを書くことが可能であり，また受信側プロセスからみた場合，常時受信データを通信バッファから読み込むことが可能である</strong>。</li>
<li>受信すべきメッセージがバッファ内に存在するか否かをフラグで判断
<ul>
<li>フラグが立っている間，送信側は新たに送信を行わない-&gt;上書き回避。</li>
<li>フラグが降りている間，受信側は新たに順を行わない-&gt;再受信回避。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>プロセス競合</strong>：複数プロセスで有限リソースを取り合う。調停し，各プロセスに適切にリソース割り当て。</p>
<ul>
<li>プロセス間での命令実行順に起因する矛盾
<ul>
<li>変数から値を読んで，変数に値を書くまでの間に，他のプロセスが変数を読んでしまう。
<ul>
<li>他のプロセスからみて，変数は変化していない。</li>
<li>実際は変化させるための手続きが始まっている。</li>
</ul>
</li>
</ul>
</li>
<li>解決するには，
<ul>
<li>共有変数の内容をレジスタ内に読み込み，演算をし，結果を共有変数に格納する一連の処理の実行において，3命令を分解できないような制御が必要。</li>
<li><strong>クリティカルセクション</strong>：このような分割してはいけない一連の処理。</li>
<li><strong>排他制御(mutual exclusion)</strong>：クリティカルセクションなどを他のプロセスと排他的に実行するための制御。</li>
</ul>
</li>
</ul>
<p><strong>プロセス干渉</strong>：他のプロセス影響で異常が発生すること。原因はプログラムのバグ。</p>
<h2 id="排他制御">排他制御</h2>
<p>クリティカルセクションなどを他のプロセスと排他的に実行するための制御。</p>
<p>重要な性質</p>
<ul>
<li>即時性
<ul>
<li>クリティカルセクションの実行に競合するプロセスが他にない場合，プロセスはクリティカルセクションの実行を直ちに許可される。</li>
</ul>
</li>
<li>デッドロック防止
<ul>
<li>競合するプロセスがある場合でも，許可されるまで永久に待たされてはいけない。</li>
</ul>
</li>
<li>公平性
<ul>
<li>どのプロセスも，他のプロセスがクリティカルセクションを実行することを防げられない。</li>
</ul>
</li>
</ul>
<p><strong>エントリーシーケンス</strong>：クリティカルセクジョンに入る権利を獲得する一連の処理。<br>
<strong>イグジットシーケンス</strong>：クリティカルセクションから出るための処理。</p>
<p>フラグによる制御：</p>
<ul>
<li>クリティカルセクションに入ろうとするプロセスは，フラグを確認し，入れるかどうかを決定。</li>
<li>入ると同時にフラグを下げる</li>
<li>以上の２つの処理自体が分割できない操作である。</li>
</ul>
<h2 id="dekkerのアルゴリズム">Dekkerのアルゴリズム</h2>
<p>２プロセスの排他制御を行うことを可能する。</p>
<p><strong>Interest</strong>：</p>
<ul>
<li>プロセスA，Bがクリティカルセクションに興味があるか否かを示す。</li>
<li>まずクリティカルセクションに入る前に，クリティセクションに入りたい皆を宣言。競合者がいなければ入れる。</li>
</ul>
<p><strong>Priorityt</strong>：</p>
<ul>
<li>プロセスA，Bがクリティカルセクションに同時に興味を持った場合，どちらを優先するかを決定する。</li>
<li>自分に優先度が回ってくるまでInterest状態を解除。</li>
</ul>
<p>ポイント：</p>
<ul>
<li>入る前に手を挙げる。</li>
<li>優先権により競合を解決。</li>
</ul>
<p><strong>問題点</strong>：</p>
<ul>
<li>ユーザプログラムに依存
<ul>
<li>ちゃんとプロセスが約束を守ってくれないと破綻。</li>
</ul>
</li>
<li><strong>ビジーウェイト（busy　wait）</strong>
<ul>
<li>一方がクリティカルセクションを実行中，待っている方は優先権をひたすらチェックし続ける-&gt;CPUリソースの無駄。</li>
</ul>
</li>
<li>最近はメニューコアが主流。CPUリソースが余っているためビジーウェイトが必ずしも悪ではない状況が発生
<ul>
<li><strong>ビジーウェイトの利点</strong>
<ul>
<li><strong>リソースが空いた時の反応が早い</strong></li>
<li>スピンロック</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="割り込み制御による排他制御">割り込み制御による排他制御</h2>
<p>単一プロセッサシステムの場合，</p>
<ul>
<li>割り込みのみがプロセス中断を発生させる
<ul>
<li>エントリシーケンスで，割り込み禁止命令を実行しておけば良い</li>
<li>同様にイグジットシーケンスで割り込み禁止を解除</li>
</ul>
</li>
<li>ただし
<ul>
<li>割り込み禁止時間の増加はシステムの性能に影響</li>
<li>OS実行の自由度が少なくなり，応答時間が増加。</li>
<li>長時間割り込みが禁止された場合，入出力要求への対応ができなくなり，OSが停止する可能性がある。</li>
</ul>
</li>
</ul>
<h2 id="ハードウェアによる排他制御">ハードウェアによる排他制御</h2>
<p>対話処理の重要性から排他制御の必要性が認識される</p>
<p><strong>テストアンドセット命令</strong>：</p>
<ul>
<li>ハードウェア自体に，排他制御のための仕組みを</li>
<li>v = test_and_set(x)
<ul>
<li>v = x と x = 0を同時に実行する命令</li>
</ul>
</li>
<li>競合者フラグのチェックとセットを同時に行える。</li>
<li><strong>２つの変数に同時に作用することにより，非常に少ないソフトウェアの実行コストでの排他制御が実現可能になった。</strong></li>
</ul>
<hr>
<p>1.複数のプロセスを同時に実行する環境においては，<strong>プロセス競合</strong>，<strong>プロセス協調</strong>が重要となる。これらの解決には，プロセス間の同期手法が基本となる。</p>
<p>2.プログラムが中断されることにより，プロセス競合が起こる可能性のあるプログラム領域を<strong>クリティカルセクション</strong>と呼ぶ。クリティカルセクション実行中は，他のプロセスが同時にクリティカルセクションに入らないように**排他制御(MUTEX)**を行う必要がある。</p>
<p>3.ソフトウェアによる排他制御の基本的な手法として，Dekkerのアルゴリズムがある。しかし，このアルゴリズムの問題点としては<strong>ビジーウェイテイング</strong>がある。</p>
<p>4.クリティカルセクションの前後で割り込みを禁止することによる排他制御の実現手法は，システムの性能に影響を及ぼす場合が多いので，できる限り利用は避けるべきである。</p>
<p>5.排他制御を実現するためのハードウェア支援として**テストアンドセット（TS）**命令が開発され，現在でも排他制御のための基本命令である。</p>
<p>4.1 排他制御を行う手法として，割り込み禁止命令を用いる方法がある。この方法の利点と欠点を挙げよ。<br>
　利点：プログラミングが容易である。欠点：長時間の割り込み禁止はシステム性能の低下につながる。</p>
<p>4.2 排他制御を実現するための命令追加について，TS命令がSWAP命令に比べて容易に実現できることを示せ。<br>
　SWAP命令は，２つのレジスタを交換するため。以下のような命令操作が必要となる。<br>
TEMP    &lt;-  R1<br>
R1      &lt;-  R2<br>
R2      &lt;-  R1<br>
　これは。CPU内で3回のデータ転送が必要であることを示している。現在はデータ転送を1回とするRISCアーキテクチャが主流のため，容易に実装することは困難であり，3回のデータ転送を1命令で行う専用回路が必要となる。<br>
　一方，TS命令の命令操作は以下である。<br>
R2 &lt;-   R1<br>
R1 &lt;-   &quot;0&quot;<br>
　１行目は通常のレジスタ転送であり，CPUのハードウェア拡張は必要としない。さらに，0をレジスタに代入するのはGNDレベルを用いて代入操作ができるため，データ転送のための特別な回路も必要としない。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[OS：CPUの仮想化ースケジューリング]]></title>
        <id>https://zy080080.github.io/post/RWPOSZYfW/</id>
        <link href="https://zy080080.github.io/post/RWPOSZYfW/">
        </link>
        <updated>2021-01-14T06:48:50.000Z</updated>
        <summary type="html"><![CDATA[<p>教科書第3章　まとめ</p>
]]></summary>
        <content type="html"><![CDATA[<p>教科書第3章　まとめ</p>
<!-- more -->
<h2 id="プロセス中断方式">プロセス中断方式</h2>
<p><strong>プリエンプション方式</strong>：OSが実行中のプロセスの実行権を強制的に取り上げることにより，プロセスを中断させる方式。（Windows　XP以降，UNIX，Mac OSなど）</p>
<p><strong>ノンプリエンプション方式</strong>：OSではなく，実行中のプロセスが自主的にCPUリソースをOSに戻す方式。この方式によるマルチタスク（マルチプログラミング）の実装は容易であるが，もしプログラムの暴走により，自発的なCPUリソースの返還がない場合は，<strong>システムの停止に繋がる</strong>。</p>
<h2 id="スケジューリングの目的">スケジューリングの目的</h2>
<p>リソースを効率的に利用するために，効率の良いスケジューリングが必要。</p>
<p>スケジューリングアルゴリズムの効率化の指標：</p>
<ul>
<li><strong>応答時間</strong>
<ul>
<li>その定義は，対象処理がバッチ処理か対話処理かどうかで異なる。
<ul>
<li>バッチ処理の場合，ジョブが投入してから結果を受け取るまでの時間と定義され，<strong>ターンアラウンドタイム</strong>とも呼ばれる。</li>
<li>対話処理の場合，端末から命令を入力した後に，コンピュータシステムから結果を受け取るまでの時間と定義され，<strong>レスポンスタイム</strong>とも呼ばれる。</li>
</ul>
</li>
</ul>
</li>
<li><strong>スループット</strong>
<ul>
<li>単位時間に行われるユーザに有益な仕事量。ただし，プロセスを切り替えるときのオーバーヘッドなど，ユーザの仕事に直接関係しない仕事は仕事量に含まれない。</li>
</ul>
</li>
</ul>
<p>応答時間とスループットは相反することもある。例えば，レスポンスタイムを向上させるためには，対話処理を実行するプロセスに，非常に短い間隔でCPUリソースを与えるようなスケジューリングアルゴリズムが有効である。しかし，このようにクオンタムの非常に小さいスケジューリング手をスループットの面から見た場合，頻繁なプロセス切り替え操作はオーバーヘッドの増加に繋がる。<br>
一方，スループットを向上させるためには，入出力操作やコンテキスト切り替えなど，オーバーヘッドの対象となるような操作をできる限り排除し，計算処理そのものにCPUリソースを用いることが有効となる。</p>
<p><strong>応答時間向上を追求-&gt;対話型処理を優先的に-&gt;TSSクオンタムを短く-&gt;切り替え回数増加，切り替えオーバーヘッド増加-&gt;スループット低下</strong></p>
<h2 id="様々なスケジューリング方式">様々なスケジューリング方式</h2>
<p><strong>FIFO(First In First Out)到着順スケジューリング，FCFS(First Come First Served)</strong>：</p>
<ul>
<li>特徴：
<ul>
<li>単純：プロセス選択機構も簡単になるし，選択オーバーヘッドも小さい</li>
<li>公平：追い抜き禁止</li>
</ul>
</li>
<li>欠点：ターンアラウンドタイムはよくない
<ul>
<li>待ち行列が100s,1s,1s,1sの時平均待ち時間27s</li>
<li>待ち行列が1s,1s,1s,100sの時平均待ち時間102s</li>
</ul>
</li>
</ul>
<p><strong>SPTF(Shortest Processing Time First)処理時間順スケジューリング</strong>：</p>
<ul>
<li>待ち行列内プロセスを処理時間順でソート</li>
<li>特徴：応答時間最短，理想的</li>
<li>欠点：実装不可能，各プロセスの処理時間を事前に知ることができない。
<ul>
<li>経験則（heuristic）から近似的に処理時間を求める。</li>
<li>近似実装：すでに実行した時間から。入出力処理から。</li>
</ul>
</li>
<li>亜種：残り処理時間順（SRTF）</li>
</ul>
<p><strong>PS(Priority Scheduling)優先度順スケジューリング</strong>：</p>
<ul>
<li>各プロセスに優先度を付加
<ul>
<li><strong>静的優先度</strong>：プロセス生成時に指定した優先度を使用。
<ul>
<li>例：プロセスの種類ごとに優先度を規定。リアルタイムプロセス&gt;OS&gt;対話型&gt;バッチ</li>
</ul>
</li>
<li><strong>動的優先度</strong>：プロセス実行中に優先度を適宜変化
<ul>
<li>例：既実行時間に応じて優先度を変化。入出力操作直後のプロセスの優先度を高く。</li>
</ul>
</li>
</ul>
</li>
<li>利点：優先度を適切に設定できれば非常に有効。</li>
<li>欠点：高負荷時，優先度の低いプロセスがなかなか実行権を獲得できない（starvation）-&gt;<strong>待ち時間に応じた優先度変化(agingエージング)などで対処</strong>。</li>
</ul>
<p><strong>RR(Round Robin)ラウンドロビン</strong>：</p>
<ul>
<li>TSSで用いられる方式。</li>
<li>待ち行列から選択されたプロセスに，微小なCPU利用時間（クオンタム）を割り当て。</li>
<li>クオンタム-&gt;無限大：RR＝FIFO</li>
<li>クオンタム＝極小：処理時間の短いプロセスに有利</li>
</ul>
<p><strong>MLF(Muti-Level Feedback)多重レベルフィードバック</strong>：</p>
<ul>
<li>Multi-Level Feedback (from Multics Project)
<ul>
<li>優先度別に待ち行列を用意。</li>
<li>プロセスは，クオンタムを得るごとにより優先度の低い待ち行列に移される。</li>
</ul>
</li>
<li>Multi-Level Feedback
<ul>
<li>複数のクオンタムを必要とするようなプロセス（すなわち長い時間がかかるプロセス）は，どんどん優先度が下がってゆく。</li>
<li>SPTFの良い近侍になっている。</li>
</ul>
</li>
</ul>
<hr>
<p>1.CPUスケジューリングには，<strong>到着順スケユーリング</strong>，<strong>処理時間順スケジューリング</strong>，<strong>優先度順スケジューリング</strong>，<strong>ラウンドロビン(Round-Robin)スケジューリング</strong>，<strong>多重レベルフィードバックスケジューリング</strong>などの方式があり，OSが用いられる環境によって様々なスケジューリングが適用されている。スケジューリング自体，１秒間に数十から数百回行う処理であり，スケジューリングの効率とともに，高速性も同時に要求される。</p>
<p>2.<strong>処理時間順スケジューリング</strong>は，理論上応答時間を最小にすることが知られている。しかし，プロセスの処理時間を，実行前に知ることは不可能である。そこで，既実行時間の少ないプロセスは，処理時間も少ないという経験的な法則を用い，近似的な処理時間順スケジューリングが用いられる。</p>
<p>3.優先度には，プロセスの生成時に決まる<strong>静的優先度</strong>と，実行中に変化する<strong>動的優先度</strong>がある。通常の対話処理では，この２つの優先度を用いてスケジューリングする場合が多い。優先度スケジューリング時には，スタベーションの問題を解決するためにエージングが併用されることが多い。</p>
<p>3.1 次の文の括弧を埋めよ（下線部の後では下線部の意味に対応する言葉を書くこと）<br>
　プロセスのスケジューリング手法の一例として，残り処理時間順(SPT)スケジューリングがある。これは処理時間の短いプロセスから順に実行する方式であり，理論上は応答時間を最小にすることができる。この方式ではあるプロセスが実行中でも，より処理時間の短いプロセスが入ってきた場合には，（実行中のプロセスはオペレーティングシステムにより中断）（<strong>プリエンプション</strong>）される。<br>
　優先度スケジューリングにおいては，優先度の低いプロセスになかなか実行権が回ってこない場合がある。この現象を（スタベーションstarvation）と呼び，通常（<strong>エージング</strong>）を併用することより回避する。</p>
<p>3.2 リアルタイム処理に用いられるデッドラインスケジューリングについて調べよ。<br>
　プロセスの実行に終了目標時間（deadline）を設定し，目標時間に近づくと，プロセスの優先度を上げて該当プロセスにCPUリソースが配分されやすいようにするスケジューリング。この方式だけでは処理のリアルタイム性を厳密に保証することは困難であるが，近似的な実装手法としてよく用いられる。</p>
]]></content>
    </entry>
</feed>