<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://zy080080.github.io/</id>
    <title>听故事的人</title>
    <updated>2021-01-18T10:36:08.484Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://zy080080.github.io/"/>
    <link rel="self" href="https://zy080080.github.io/atom.xml"/>
    <subtitle>天青色等烟雨，而我在等你</subtitle>
    <logo>https://zy080080.github.io/images/avatar.png</logo>
    <icon>https://zy080080.github.io/favicon.ico</icon>
    <rights>All rights reserved 2021, 听故事的人</rights>
    <entry>
        <title type="html"><![CDATA[OS：主記憶管理ーセグメンテーション，ページかセグメンテーション]]></title>
        <id>https://zy080080.github.io/post/zAjTn6PkI/</id>
        <link href="https://zy080080.github.io/post/zAjTn6PkI/">
        </link>
        <updated>2021-01-18T11:35:35.000Z</updated>
        <summary type="html"><![CDATA[<p>教科書第10章　まとめ</p>
]]></summary>
        <content type="html"><![CDATA[<p>教科書第10章　まとめ</p>
<!-- more -->
<p><strong>多重レベルページング</strong>：</p>
<ul>
<li>従来のページングにおける，仮想アドレスの「ページ番号部」を複数に分割</li>
<li>それぞれをページ番号として階層化したテーブルを検索</li>
<li>必要なテーブルのみを主記憶上に置くことで，主記憶使用量を削減（残りは仮想記憶へ）</li>
<li>ただし，多段化により，主記憶アクセスは増加 =&gt;TLBにより解決</li>
</ul>
<p><strong>0レベルページング（連想写像方式）</strong>：</p>
<ul>
<li>一般的なページング
<ul>
<li>主記憶上にページテーブル</li>
<li>CPU内のMMUが，ページテーブルを用いてアドレス変換</li>
</ul>
</li>
<li>0レベルページング
<ul>
<li>ハードウェアとしてのMMUを持たない</li>
<li>一般的なページテーブルを持たず，連想メモリで構成したTLBでアドレス変換</li>
</ul>
</li>
<li>メリット
<ul>
<li><strong>高クロック</strong>実装が可能
<ul>
<li>MMU不要のため，CPU機構が単純化</li>
</ul>
</li>
</ul>
</li>
<li>デメリット
<ul>
<li>TLBヒットしなかった場合のオーバーヘッドが膨大
<ul>
<li>ソフトウェア処理のため</li>
</ul>
</li>
</ul>
</li>
<li>よって
<ul>
<li>主記憶使用量の少ないプログラムには<strong>高速</strong></li>
<li>主記憶使用量の多いプログラムには<strong>非常に低速</strong></li>
</ul>
</li>
</ul>
<p><strong>セグメンテーション</strong>：</p>
<p>ページングの上，プログラム部，データ部，スタック部などの分離とプロセス間で共有を実現する。</p>
<ul>
<li>ページ（ページング）
<ul>
<li>一定の大きさを割り当て単位とする</li>
</ul>
</li>
<li>セグメント（セグメンテーション）
<ul>
<li>プロセスに対し<strong>複数</strong>のセグメントを割り当て
<ul>
<li>各セグメントは論理的に<strong>独立</strong></li>
<li>プログラム部，データ部など固有領域として使用可能</li>
</ul>
</li>
<li>各セグメントはその論理区間の大きさを自由に<strong>増減可能</strong></li>
</ul>
</li>
<li>利点
<ul>
<li>プログラム部，データ部など，用途別に複数をプロセスに割り当て</li>
<li>各セグメンテーションは大きさを増減可能</li>
</ul>
</li>
<li>欠点
<ul>
<li>フラグメンテーション</li>
</ul>
</li>
</ul>
<p><strong>ページ化セグメンテーション</strong>：</p>
<ul>
<li>セグメンテーションを複数のページにより構成する。</li>
<li>セグメントごとにページテーブルを用意</li>
<li>利点：
<ul>
<li>フラグメンテーションの回避
<ul>
<li>主記憶割り当ては基本的にページ単位</li>
</ul>
</li>
<li>複数セグメント
<ul>
<li>各セグメントは大きさ増減可能</li>
<li>複数使用により，用途別に使い分け可能</li>
</ul>
</li>
<li>プロセス間共有
<ul>
<li>セグメンテーションとほぼ同様に共有可能<br>
　- ページテーブルの分散</li>
<li>ページテーブルが複数に分割されるので，多重レベルページング同様，その一部を<strong>仮想記憶に追い出すことで主記憶使用量削減</strong></li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h2 id="ポイント">ポイント</h2>
<p>1.高級言語では，プログラム領域，データ領域，スタック領域，動的データ領域など複数のアドレス空間を用いる。<strong>セグメンテーション</strong>を用いることにより，プログラムに対して複数の異なるアドレス空間を提供することが可能である。さらに，複数のプロセス間で仮想アドレス空間を共有する共有メモリも容易に実現可能である。</p>
<p>2.<strong>ページカセングメンテーション</strong>は，ページングとセグメンテーションの両方の利点を有する方式であり，現在の主記憶管理手法の主流である。</p>
<p>3.ページングシステムでは，ページテーブルの大きさが大きくなり，主記憶領域を圧迫する。しかし，<strong>ページかセグメンテーション</strong>や<strong>多重レベルページング</strong>などでは，ページテーブルも仮想記憶内で管理するため，解決可能である。</p>
<p>4.最小限のハードウェアで高性能を得るために開発され，MIPS社のR2000で採用された0レベルページングは，ページテーブルの管理を，ハードウェアで実装されたMMUではなく，ソフトウェア割り込みで実装した。</p>
<p>10.1　多重レベルページングと仮想記憶を用いることにより，主記憶内に存在するページテーブルの大きさが無視できることを示せ。<br>
　多重レベルページングを用いることにより，各プロセスが必要とするページテーブル自体も仮想記憶の対象となる。つまり，全てのページテーブルのうち，直近にアクセスされたページテーブルの一部のみが主記憶に存在することになる。したがって，プロセスが現時点で必要としているページテーブル部分のみが主記憶に配置される。</p>
<p>10.2　ページ化セグメンテーションにおいて，外部・内部フラグメンテーションの問題について説明せよ。<br>
　ページ化セグメンテーションは主記憶の割り当てはページ単位の固定長割り当てなので，外部セグメンテーションは存在しない。しかし，プロセスには主記憶をページ単位で割り当てるため，例えばページサイズが8kBの場合，複数割り当てたページ群の最後のページで平均4KBの未使用領域（内部フラグメンテーション）が発生する。しかし，現在のプロセスに必要な主記憶量に比べると無視できる量である。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[OS：主記憶管理ーページング]]></title>
        <id>https://zy080080.github.io/post/M7ToAnBlI/</id>
        <link href="https://zy080080.github.io/post/M7ToAnBlI/">
        </link>
        <updated>2021-01-18T06:23:01.000Z</updated>
        <summary type="html"><![CDATA[<p>教科書第9章　まとめ</p>
]]></summary>
        <content type="html"><![CDATA[<p>教科書第9章　まとめ</p>
<!-- more -->
<p><strong>仮想記憶</strong>：主記憶の動的再配置により，プロセスが使用できる主記憶領域を無限大にする方式。</p>
<p><strong>仮想アドレス</strong>：記憶容量に制限のない論理アドレス。</p>
<p><strong>スワップイン</strong>：</p>
<ul>
<li>実行中のプログラムが必要となる領域を二次記憶から主記憶に転送する操作。</li>
</ul>
<p><strong>スワップアウト</strong>：</p>
<ul>
<li>スワップインを行う際，その空き領域を確保するために，当面必要としない領域を主記憶から二次記憶に転送する操作。</li>
</ul>
<p>記憶領域の仮想化</p>
<ul>
<li>仮想アドレス空間の一部が物理メモリに存在</li>
<li>仮想アドレスと物理アドレスの対応付けが必要</li>
<li>物理メモリ上に存在する「仮想記憶の一部」は時々刻々変化する（<strong>動的再配置</strong>）</li>
<li>対応付けも時々刻々へ変化</li>
</ul>
<p><strong>ページング</strong>：ロック/キー機構に動的再配置機能を加えた方式である。</p>
<p><strong>ページ</strong>：<strong>仮想アドレス</strong>を上位部と下位部に分割することによって生成されたブロック単位。</p>
<p><strong>ページフレーム</strong>：<strong>物理アドレス</strong>を上位部と下位部に分割することによって生成されたブロック単位。</p>
<p><strong>ページテーブル</strong>：ページ番号からページフレーム番号へのマッピングを行うテーブル。</p>
<p>仮想アドレスは通常プロセスごとに独立して存在する多重仮想記憶として実装される。したがって，ページテーブルもプロセスごとに複数必要となり，書くプロセスのPSW情報中に，主記憶中のどこに自プロセスのページテーブルが格納されているかを示すポインタ情報を格納する<strong>ページテーブルレジスタ</strong>がある。</p>
<p>フラグ</p>
<ul>
<li><strong>Vフラグ</strong>（Virtual Memory Flag）
<ul>
<li>そのページが主記憶に存在するか否かを示す</li>
<li>1の場合はスワップインが必要</li>
</ul>
</li>
<li><strong>Pフラグ</strong>（Permission Flag）
<ul>
<li>そのページに対するアクセス条件を表す</li>
<li>例：001（読み込み可）010（書き込み可）100（実行可）</li>
</ul>
</li>
<li><strong>Cフラグ</strong>（Change Flag）
<ul>
<li>スワップイン後，そのフレームに対して書き込みが行われたか（変更されたか）否かを表す</li>
<li>1の場合は，スワップアウト時に二次記憶へのフレームの書き戻しが必要</li>
</ul>
</li>
</ul>
<p>プロセスはページ単位でしかメモリ量を要求でいないため，メモリフラグメンテーションの問題は発生しない。<br>
<strong>内部フラグメンテーション</strong>：割り当てられたが，使用されない領域。</p>
<ul>
<li>一ページが4~8kB程度なので，主記憶の全容量からすると微々たる大きさ，ほとんど無視できる。</li>
</ul>
<p><strong>ページングの問題点</strong>：</p>
<ul>
<li>ページテーブルの巨大さ
<ul>
<li>例）仮想アドレス32bit，1ページ8kBの場合
<ul>
<li>ページエントリ数：50万</li>
</ul>
</li>
<li>ページテーブルはプロセス毎に独立
<ul>
<li>例）100プロセスの場合のエントリ数：5000万，1エントリ10Bで構成すると500MB</li>
</ul>
</li>
<li>解決法：
<ul>
<li>ハッシュ関数によるページテーブル</li>
</ul>
</li>
</ul>
</li>
<li>メモリアクセスの増大
<ul>
<li>ページテーブルは主記憶内に存在</li>
<li>1回で２度の主記憶アクセスが必要
<ul>
<li>ページテーブルへのアクセス</li>
<li>物理アドレスへのアクセス</li>
</ul>
</li>
<li>解決法：
<ul>
<li>連想レジスタ方式</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>連想レジスタ</strong>（TLB：Translation Lookaside Buffer）：</p>
<ul>
<li>最近行われた変換結果をCPU内で保持</li>
<li>小容量で高速</li>
<li>一般的にプログラムは，「<strong>一度アクセスしたアドレスを近いうちに再度アクセスする可能性が高い</strong>」ことを利用</li>
</ul>
<p>アクセス速度の違い</p>
<ul>
<li>CPU基本サイクル   約10^(-9)秒</li>
<li>CPUが主記憶へアクセスする速度 約10^(-7)秒</li>
<li>スワップイン・スワップアウトで二次記憶へアクセス速度  約10^(-3)秒</li>
</ul>
<hr>
<p>1.主記憶の再配置機能を持つ<strong>ページング</strong>は，現在用いられている主記憶管理の基本である。仮想アドレスの上位をページ番号部，下部をオフセット部とし，ページ番号部は，ページテーブルを参照して，物理アドレスであるページフレーム番号に変換される。また，ページテーブルには各ページごとにアクセス制御グラフなどが配置され，ページのアクセス権を設定することができる。</p>
<p>2.ページングは，仮想記憶が実現できるとともに，メモリフラグメンテーション問題も解決可能である。しかし，ページテーブルを主記憶に配置する必要があるため，主記憶へのアクセス速度が低下する可能性がある。アクセス速度を低下させないために，<strong>TLB</strong>（<strong>連想レジスタ</strong>）を用いる。</p>
<p>3.ページテーブルを主記憶上に全て配置した場合，その大きさが無視できなくなる。主記憶上のページテーブルを削減するとして，ハッシュ関数を用いて，現在主記憶上にあるページフレームを管理するページテーブルのみを主記憶上に配置する方式がある。</p>
<p>4.仮想記憶の利用を前提とした場合，主記憶のアクセス速度と，２次記憶のアクセス速度に注意する必要がある。両者のアクセス速度は数万倍の差があり，過度な仮想記憶の利用はできる限り避けるべき。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[OS：主記憶管理ー主記憶割り当て]]></title>
        <id>https://zy080080.github.io/post/ES4qIO3DM/</id>
        <link href="https://zy080080.github.io/post/ES4qIO3DM/">
        </link>
        <updated>2021-01-17T15:41:41.000Z</updated>
        <summary type="html"><![CDATA[<p>教科書第8章　まとめ</p>
]]></summary>
        <content type="html"><![CDATA[<p>教科書第8章　まとめ</p>
<!-- more -->
<p>領域要求のタイミング：</p>
<ul>
<li>静的（static）要求
<ul>
<li>プログラム実行開始時に必要領域を要求</li>
</ul>
</li>
<li>動的（dynamic）要求
<ul>
<li>プログラム実行開始時に最低限の領域を要求</li>
<li>実行につれてさらに必要となった場合はその都度要求</li>
</ul>
</li>
</ul>
<p><strong>固定区画方式</strong>：</p>
<ul>
<li>プロセスに割り当てる領域の大きさをあらかじめ決めておく</li>
<li>プロセスから要求があった際，その決められた大きさの領域を割り当てる</li>
<li>特徴：
<ul>
<li>新しいプロセスの生成時に，領域を割り当てるコストが非常に少ない（選択の幅がない）</li>
</ul>
</li>
<li>欠点：
<ul>
<li>小規模の主記憶領域しか必要としないプロセスにとっては，利用しない領域まで割り当ての対象となり，結果としてOS全体で考えた場合の主記憶領域の使用効率が低下する。</li>
</ul>
</li>
</ul>
<p><strong>可変区画方式</strong>：</p>
<ul>
<li>プロセスは，必要な分だけ領域を要求</li>
<li>プロセスごとに要求サイズは異なる</li>
<li>要求があった分だけ割り当てる</li>
<li>問題点
<ul>
<li>空き領域の検索コスト
<ul>
<li>処理が進行するに従い，様々な大きさの空き領域が発生</li>
<li>新しいプロセスの要求に合う大きさの空き領域を探すコストが増大</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>断片化（フラグメンテーション）</strong>：</p>
<ul>
<li>プロセスからの要求サイズは異なるため，可変区画方式で眼持ちを割り当てると，プロセスが使えない大量の小さな領域が残ってしまう現象。</li>
<li>解決法：<strong>メモリコンパクション</strong>
<ul>
<li>メモリを確保しているプロセスの実行を止めた後に，断片化した領域を１つの連続した領域にまとめる。</li>
</ul>
</li>
</ul>
<p>可変区画方式における空き領域管理：</p>
<ul>
<li><strong>ベストフィット方式</strong>
<ul>
<li>割り当てた残り領域がもっとも少なくなる空き領域に割り当てる方式</li>
<li>一番効率的に見えるが</li>
<li>欠点
<ul>
<li>空き容量の探索コストが大きくなる場合がある</li>
<li>残った領域が小さすぎて他のプロセスが使用できない確率が高い</li>
</ul>
</li>
</ul>
</li>
<li><strong>ワーストフィット方式</strong>
<ul>
<li>割り当てた残り領域がもっとも大きくなる空き領域に割り当てる方式</li>
<li>残った領域は，ベストフィット方式より比較的大きくなる</li>
<li>欠点
<ul>
<li>処理が進むにつれ空き領域の大きさが均一化し，大きい要求に応じられない</li>
</ul>
</li>
</ul>
</li>
<li><strong>ファーストフィット方式</strong>
<ul>
<li>要求された量を確保できる最初に見つかった領域を割り当てる方式</li>
<li>探索コストが小さい。主記憶領域の全てを調べる必要がない</li>
<li>アドレス上位に大きい領域が残りやすくなり，大きい要求にも対応しやすい</li>
</ul>
</li>
</ul>
<h2 id="領域管理">領域管理</h2>
<h3 id="リスト方式">リスト方式</h3>
<table>
<thead>
<tr>
<th style="text-align:center">アドレス：A1</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">サイズ：S1</td>
</tr>
<tr>
<td style="text-align:center">next</td>
</tr>
</tbody>
</table>
<p>アドレス順リストの場合：ファーストフィット方式での検索が高速。<br>
大きさ順リストの場合：ベストフィット方式での検索が高速。</p>
<h3 id="ビットマップ方式">ビットマップ方式</h3>
<p>空き情報を示す配列</p>
<ul>
<li>ビットマップ
<ul>
<li>記憶領域を単位ブロックに分割
<ul>
<li>例：アドレスの上位数ビットが共通の部分など</li>
</ul>
</li>
<li>各領域に対応するビットを用意</li>
</ul>
</li>
<li>ビット配列により，主記憶全体の空き領域を表現
<ul>
<li>大きい連続した空き領域を検索する際は
<ul>
<li>フラグに０が続いている部分を探索</li>
</ul>
</li>
<li>各要素へのアクセスは高速だが，<strong>空き領域の検索コストが大きくなりがち</strong></li>
</ul>
</li>
</ul>
<h2 id="プログラムのロードと領域の再配置">プログラムのロードと領域の再配置</h2>
<p>プログラム記述から実行までの流れ：<br>
通常はリンケージエディタにおいてユーザがプログラム中に使ったライブラリ関数を結合し，即時実行可能形式（<strong>ロードモジュール</strong>）として，ファイルに格納されるとともに，実行時にはこのイメージのまま主記憶にロードされる。</p>
<p><strong>静的ライブラリ</strong></p>
<ul>
<li>リンク時にロードモジュールに<strong>埋め込み</strong>（静的リンク）</li>
<li>複数プログラムで使用されるライブラリがある場合，主記憶領域の無駄</li>
</ul>
<p><strong>共有ライブラリ</strong>：</p>
<ul>
<li>主記憶内にロードされた複数のプログラムから共有可能なライブラリ。</li>
<li>リンカはロードモジュールにライブラリの埋め込みを行わない。</li>
<li>共有ライブラリに対するリンク情報のみロードモジュールに書き込む</li>
<li>ロードモジュールは<strong>リンク情報のみ</strong>を持ち，<strong>実行時にリンク</strong>（ダイナミックリンク）</li>
<li>複数プログラムで使用される場合でも，各ライブラリは１つのイメージだけ主記憶上に存在すればよい</li>
<li>主記憶領域（およびディスク領域）の有効活用</li>
<li>共有ライブラリが<strong>リエントラント</strong>である</li>
</ul>
<p><strong>リエントラント性</strong></p>
<ul>
<li>複数のプログラム間で同一関数を共有するには，あるプログラムがその関数を実行中に中断された後，他のプログラムが同一関数を実行した後であっても，中断直後の状態から同一関すを再開できる必要がある。</li>
<li>複数のプログラムが主記憶上にロードされた変数を同時に利用可能な性質を<strong>リエントラント性</strong>(再入可能性)と呼ぶ。</li>
<li>各呼び出しごとに，作業領域を保存する仕組みが必要
<ul>
<li>関数内でグローバル偏すをアクセスしない。関数内でstaticな変数を使わないなど。</li>
</ul>
</li>
</ul>
<p><strong>実行時結合</strong>：実行時にリンク操作を行う</p>
<p><strong>リロケータブル（再配置可能）</strong>：プログラム本体が，主記憶上の任意の位置に配置（ロード）されても実行可能である性質。</p>
<ul>
<li>この場合，プログラム内の全てのアドレス指定が，プログラムの先頭のアドレスからの相対位置で表現されている必要がある。</li>
</ul>
<p><strong>共有ライブラリの現状</strong></p>
<ul>
<li>共有ライブラリは，主記憶の効率的利用という観点からは望ましい</li>
<li>しかし，プログラム（ライブラリ）全てがリエントラント性を満たすためには相当な書き換えが必要。</li>
<li>現状
<ul>
<li>ダイナミックリンク（単体）は，利用されている
<ul>
<li>２次記憶の有効利用</li>
<li>脆弱性対応時の容易性 =&gt;ライブラリだけを配布すれば良い（例　Windows　DLL）</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="オーバーレイ">オーバーレイ</h2>
<p>オーバーレイ</p>
<ul>
<li>指定した時刻に，アプリケーションのどの部分が主記憶上に存在すべきかをプログラマが指定する仕組み</li>
<li>毎に実行されたコード（親関数など）のうち，さしあたり(目前)必要のなくなったコードがロードされている主記憶領域に対して，新しく必要となったコードを上書き（overlay）できる</li>
<li>欠点
<ul>
<li>非常に複雑でエラーを起こしやすい</li>
<li>プログラマの負担が増大</li>
</ul>
</li>
</ul>
<p>軽量に仮想記憶を実装できるオーバーレイはIoTなどの分野で今後も重要な位置を占める</p>
<hr>
<p>1.マルチプログラミング環境では，プログラムの発生，消滅が頻繁に起こるため，プログラム（およびデータ）を格納する領域を管理する方式が重要となる。</p>
<p>2.メモリの割り当て方式には，あらかじめ決められたシステムで決めた大きさの領域を全てのプロセスに平等に割り当てる<strong>固定区画方式</strong>と，プロセスが要求する大きさの領域を与える可変区画方式がある。</p>
<p>3.可変区画方式において，もし適切な管理を行わないと，プロセスが使えない断片的なメモリ領域が数多く発生する<strong>メモリフラグメンテーション</strong>が起こる。</p>
<p>4.空き領域を管理する方法として，リストデータ構造を用いるリスト方式と，配列を用いる<strong>ビットマップ方式</strong>がある。また，割り当て方式として，<strong>ベストフィット方式</strong>，<strong>ファーストフィット方式</strong>，<strong>ワーストフィット方式</strong>がある。</p>
<p>5.マルチプログラミング環境では，主記憶を効率よく利用するために，複数のプログラムが，主記憶中にロードされたライブラリを共有できる<strong>共有ライブラリ</strong>が有効な手法である。共有ライブラリを実現するためには，プログラムのリエントラント性，およびプログラムの実行時にライブラリを結合する<strong>ダイナミックリンク</strong>が必要である。</p>
<p>6.プログラマが明示的にプログラムの主記憶へのロードを管理し，現在実行している部分のみを主記憶にロードすることにより，プログラムの実行に必要な主記憶量を提言する方法を<strong>オーバーレイ</strong>と呼ぶ。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[OS：主記憶管理基礎]]></title>
        <id>https://zy080080.github.io/post/u3Uh6KrGp/</id>
        <link href="https://zy080080.github.io/post/u3Uh6KrGp/">
        </link>
        <updated>2021-01-17T09:24:20.000Z</updated>
        <summary type="html"><![CDATA[<p>教科書第7章　まとめ</p>
]]></summary>
        <content type="html"><![CDATA[<p>教科書第7章　まとめ</p>
<!-- more -->
<p><strong>物理アドレス空間</strong>：主記憶上の実アドレス空間。</p>
<p><strong>論理アドレス空間</strong>：プログラムからみた，各プロセスごとに独立した実アドレス空間に対応するアドレス空間。</p>
<p><strong>主記憶管理部</strong>(memory management unit：<strong>MMU</strong>)：各プロセスごとの論理アドレス空間を一次元アドレスで表現されている受寄屋上の物理アドレス空間へ変換（Mapping）を行うハードウェアである。</p>
<p><strong>ネーミング関数</strong>：</p>
<ul>
<li>変数，定数などの識別子を論理アドレスに変換する関数</li>
<li>コンパイル・リンク時に行われる</li>
</ul>
<p><strong>メモリ関数</strong>：</p>
<ul>
<li>論理アドレスから物理アドレスに変換する関数。</li>
<li>OSによって行われる</li>
</ul>
<p><strong>内容関数</strong>：</p>
<ul>
<li>物理アドレスから，そのアドレスに格納された内容に変換する関数</li>
<li>ハードウェアによって行われる</li>
</ul>
<p><strong>下限レジスタ</strong>：主記憶上のOS領域とユーザ領域の境界を示すレジスタである。</p>
<p>下限レジスタ機構とその問題点：</p>
<ul>
<li>ユーザ領域の下限を設定
<ul>
<li>下限レジスタが示す境界でOS/ユーザ領域を区別</li>
</ul>
</li>
<li>問題点
<ul>
<li>領域境界が１つしかない</li>
<li>OS領域を保護することしかできない</li>
<li>複数のプロセス間でアクセス権は設定できない</li>
</ul>
</li>
</ul>
<p>そのため，任意・複数の境界を設定し，プロセスごとにアクセス権を設定したい。 -&gt;ロック/キー機構</p>
<hr>
<p>1.<strong>主記憶管理</strong>の目的は，ユーザに独立した仮想アドレス空間を提供することである。理想的な仮想アドレス空間を持つべき特徴としては，大きさ無制限，プロセスごとに固有，プロセス間で主記憶空間を共有可，プログラム部，データ部，スタック部など複数の１次元アドレスがある。</p>
<p>2.<strong>下限レジスタ機構</strong>は，ユーザ領域とオペレーティングシステム領域を下限レジスタが示す位置で分離し，CPUの実行モードにより，オペレーティングシステム領域へのアクセスを制限する基本的な仕組みである。</p>
<p>3.<strong>ロック/キー機構</strong>は，アドレスを論理的に上位と下位に分け，上位部の内容を主記憶を示すアドレスとしてだけでなく，主記憶ブロックへのアクセス権が格納されているロックデータ配列への添字（ポインタ情報）として用いる。この考え方は，ページング，セグメンテーションによるメモリ管理の基礎である。<br>
　現在実行中のプロセスの主記憶に対するアクセス権がPSWに格納されていて，それをキー部に対応するロックデータと比較して，アクセスを許可するかどうかを決める。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[OS：並行プロセス-モニタ]]></title>
        <id>https://zy080080.github.io/post/ECsYYoE6u/</id>
        <link href="https://zy080080.github.io/post/ECsYYoE6u/">
        </link>
        <updated>2021-01-16T12:08:05.000Z</updated>
        <summary type="html"><![CDATA[<p>教科書第6章 まとめ</p>
]]></summary>
        <content type="html"><![CDATA[<p>教科書第6章 まとめ</p>
<!-- more -->
<p>モニタとセマフォ</p>
<table>
<thead>
<tr>
<th style="text-align:center">セマフォ</th>
<th style="text-align:center">モニタ</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">P命令</br>共有リソースの取得トライ。失敗時に待ち行列へ</td>
<td style="text-align:center">wait()</br>待ち行列へ</td>
</tr>
<tr>
<td style="text-align:center">V命令</br>共有リソース返却，待ちプロセスを１つ実行可能状態へ</td>
<td style="text-align:center">signal()（Javaではnotify()）</br>待ちプロセスを１つ実行可能状態へ</td>
</tr>
<tr>
<td style="text-align:center">-</td>
<td style="text-align:center">queue()</br>待ちプロセスの有無を返す</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:center">セマフォ</th>
<th style="text-align:center">モニタ</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">P命令を実行しないとセマフォの状態がわからない</td>
<td style="text-align:center">メソッドにより，共有リソースの状態を排他的に調べられる</td>
</tr>
<tr>
<td style="text-align:center">リソースを取ろうとしないと，空いているかどうか不明</td>
<td style="text-align:center">リソースの空きの確認とリソース待ちが分離</td>
</tr>
<tr>
<td style="text-align:center">取れなかったら，いきなり待ち行列に待たされる</td>
<td style="text-align:center">条件変数へのwaitにより，自由度の高い「待ち」が可能</td>
</tr>
</tbody>
</table>
<p><strong>モニタの利点（セマフォに対し）</strong>：</p>
<ul>
<li>リソース確認と「待ち」状態の分離
<ul>
<li>リソースに空きがない場合，「待ち」に入るかどうか自由に選べる</li>
</ul>
</li>
<li>排他制御すべきリソースの明示
<ul>
<li>モニタ内に記述されるため明示的</li>
<li>他の一般的な変数と判別しやすい</li>
<li>排他的メソッドを通じた処置により保護</li>
</ul>
</li>
<li>プログラマに安全で扱いやすい枠組みを提供</li>
</ul>
<hr>
<p>1.<strong>モニタ</strong>とは，オブジェクト思考の考え方を排他制御（およびプロセス同期）に適用した解法である。モニタ内には，排他制御の対象となる<strong>リソース</strong>，リソースを操作するための<strong>メソッド</strong>，オブジェクトの実体を生成する際に実行する<strong>初期コード</strong>，<strong>終了時コード</strong>が存在する。</p>
<p>2.モニタ内のリソースは，メソッドを介してのみアクセス可能である。また，各モニタのメソッドは排他的に実行される。したがって，プログラマはモニタ内のリソースの排他制御を考慮する必要はない。</p>
<p>3.モニタを用いることにより，セマフォよりもさらに抽象度が高くできるとともに，デッドロックの可能性のある処理を，コンパイラで実行前にある程度事前に検出することも可能となる。</p>
<p>複数のプロセスが，同時に実行されている場合，共通のリソース（共有変数など）にアクセスする場合は（排他制御）が必要となる。また，（排他制御）が必要となる領域のことを（クリティカルセクション）と呼ぶ。（排他制御）の解決方法の代表的な例は（セマフォ）である。これは，待ち行列と整数変数を持つデータ構造であり，（P）命令と（V）命令により制御する。一般的には，（クリティカルセクション）に入る前に（P）命令を，出る前に（V）命令を実行する。さらに，より抽象度の高い（排他制御）の方法として，（モニタ）がある。（モニタ）は，（排他制御）の対象となるリソースを（オブジェクト）指向の枠組みで抽象化したモデルである。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[OS：並列プロセス-セマフォ]]></title>
        <id>https://zy080080.github.io/post/oEPtkexau/</id>
        <link href="https://zy080080.github.io/post/oEPtkexau/">
        </link>
        <updated>2021-01-16T04:50:30.000Z</updated>
        <summary type="html"><![CDATA[<p>教科書第5章　まとめ</p>
]]></summary>
        <content type="html"><![CDATA[<p>教科書第5章　まとめ</p>
<!-- more -->
<p><strong>semaphore　セマフォ</strong>：整数型の変数（セマフォ変数）と，待ち行列からなるデータ構造を有する構造体である。この構造体へは，P命令，V命令の２つの操作が許されている。</p>
<p><strong>P命令</strong>：リソースを要求し，許可されない場合は待ち状態へ移行。</p>
<ul>
<li>空きリソースを1つ使用</li>
<li>空きリソース数（セマフォ変数）をデクリメント</li>
<li>空きがない場合，プロセスを待ち状態に</li>
</ul>
<p><strong>V命令</strong>：リソースを解放し，待ちプロセスを実行可能状態へ移行。待ちプロセスがない場合，空きリソース数をインクリメント。</p>
<ul>
<li>空きリソースを1つ解放</li>
<li>待ちプロセスを1つ実行可能状態に</li>
<li>待ちプロセスがない場合，空きリソース数（セマフォ変数）をインクリメント</li>
</ul>
<p><strong>デッドロック</strong>：全てのプロセスが，あるリソースを確保するために，別のリソースを確保したママ解放を待っている状態となってしまい，これらのリソースに関連する全てのプロセスの実行が止まってしまう状態。</p>
<p><strong>ダイニングフィロソファの解法</strong>：</p>
<ul>
<li>解法1：フォーク一本一本ではなく，「フォーク全体を使う権利」をセマフォで管理
<ul>
<li>うまくいくが，同時に一人しか食事できない。</li>
<li>実際は二人同時に食事可能な場合があるはず</li>
<li>リソースが有効利用できていない</li>
</ul>
</li>
<li>解法2：１つのプロセスだけが逆順でフォークを要求
<ul>
<li>うまくいくが，哲学者4が特殊であるため，<strong>公平性</strong>を欠いている可能性がある</li>
</ul>
</li>
<li>解法3：少し我慢をする哲学者
<ul>
<li>右のフォークを確保後，左のフォークが確保できなければ，一旦右のフォークを解放して少し待つ</li>
<li>これにより，「全員右フォークを確保した状態」から抜け出せる</li>
<li>問題点：全員が同時に「右フォーク確保，右フォーク解放」を繰り返すと，デッドロック。</li>
</ul>
</li>
<li>解法4：不定時間だけ我慢をする哲学者
<ul>
<li>右のフォークを確保後，左のフォークが確保できなければ，一旦右のフォークを解放して少し待つ</li>
<li>待つ時間はランダムに決定する</li>
<li>これによって，全員が同時に「右のフォークを確保，右のフォークを解放」を繰り返すことがなくなる</li>
<li>問題点：デッドロックが発生しないことを証明できない。フォークを解放して「譲った」哲学者は，次に優先される仕組みがないと公平性に欠ける。</li>
</ul>
</li>
<li>理想的な解法：
<ul>
<li>リソース確保に失敗した場合，当該リソースを確保するための<strong>待ち行列に並ぶことができる</strong>こと</li>
<li>全てのプロセスがリソースを<strong>平等に確保できる</strong>ことを保証すること</li>
</ul>
</li>
</ul>
<hr>
<p>1.<strong>P命令</strong>(wait)と<strong>V命令</strong>(signal)からなる<strong>セマフォア</strong>は，より抽象的な排他制御の仕組みとして開発された。セマフォを獲得できないプロセスは，待ち状態に移行するため，ビジーウェイティングの問題はない。</p>
<p>2.プロセス間通信や計算機間の通信(Local Area Network, Internetwork)をモデル化した<strong>プロデュサ/コンシューマ問題</strong>や，データベースアクセス制御をモデル化した<strong>リーダタイム問題</strong>は，非同期問題の解法として重要な例題である。</p>
<p>3.<strong>食事をする哲学者問題</strong>は，複数リソースを獲得する際のデッドロックをモデル化している。複数リソースを獲得するプログラムを作成する場合，常にデッドロックを考慮する必要がある。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[OS：並列プログラム-排他制御基礎]]></title>
        <id>https://zy080080.github.io/post/7nRN9HqLl/</id>
        <link href="https://zy080080.github.io/post/7nRN9HqLl/">
        </link>
        <updated>2021-01-16T02:33:25.000Z</updated>
        <summary type="html"><![CDATA[<p>教科書第4章　まとめ</p>
]]></summary>
        <content type="html"><![CDATA[<p>教科書第4章　まとめ</p>
<!-- more -->
<p><strong>プロセス協調</strong>：仕事の分担や通信など，複数プロセスが助け合う。</p>
<ul>
<li>プロセス間通信のための仕組み：通信バッファ
<ul>
<li>通信バッファがないと，送信側と受信側でタイミングを合わせる必要があり，受信側は，常にメッセージが来ないかをチェックしていなければならない。</li>
<li><strong>通信バッファの役割：通信バッファは，通信情報を一時的に保存する機能である。全てのプロセスからアクセスできる領域に存在し，送信側からみた場合，受信側プロセスの状態に関わらず，常時送信データを書くことが可能であり，また受信側プロセスからみた場合，常時受信データを通信バッファから読み込むことが可能である</strong>。</li>
<li>受信すべきメッセージがバッファ内に存在するか否かをフラグで判断
<ul>
<li>フラグが立っている間，送信側は新たに送信を行わない-&gt;上書き回避。</li>
<li>フラグが降りている間，受信側は新たに順を行わない-&gt;再受信回避。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>プロセス競合</strong>：複数プロセスで有限リソースを取り合う。調停し，各プロセスに適切にリソース割り当て。</p>
<ul>
<li>プロセス間での命令実行順に起因する矛盾
<ul>
<li>変数から値を読んで，変数に値を書くまでの間に，他のプロセスが変数を読んでしまう。
<ul>
<li>他のプロセスからみて，変数は変化していない。</li>
<li>実際は変化させるための手続きが始まっている。</li>
</ul>
</li>
</ul>
</li>
<li>解決するには，
<ul>
<li>共有変数の内容をレジスタ内に読み込み，演算をし，結果を共有変数に格納する一連の処理の実行において，3命令を分解できないような制御が必要。</li>
<li><strong>クリティカルセクション</strong>：このような分割してはいけない一連の処理。</li>
<li><strong>排他制御(mutual exclusion)</strong>：クリティカルセクションなどを他のプロセスと排他的に実行するための制御。</li>
</ul>
</li>
</ul>
<p><strong>プロセス干渉</strong>：他のプロセス影響で異常が発生すること。原因はプログラムのバグ。</p>
<h2 id="排他制御">排他制御</h2>
<p>クリティカルセクションなどを他のプロセスと排他的に実行するための制御。</p>
<p>重要な性質</p>
<ul>
<li>即時性
<ul>
<li>クリティカルセクションの実行に競合するプロセスが他にない場合，プロセスはクリティカルセクションの実行を直ちに許可される。</li>
</ul>
</li>
<li>デッドロック防止
<ul>
<li>競合するプロセスがある場合でも，許可されるまで永久に待たされてはいけない。</li>
</ul>
</li>
<li>公平性
<ul>
<li>どのプロセスも，他のプロセスがクリティカルセクションを実行することを防げられない。</li>
</ul>
</li>
</ul>
<p><strong>エントリーシーケンス</strong>：クリティカルセクジョンに入る権利を獲得する一連の処理。<br>
<strong>イグジットシーケンス</strong>：クリティカルセクションから出るための処理。</p>
<p>フラグによる制御：</p>
<ul>
<li>クリティカルセクションに入ろうとするプロセスは，フラグを確認し，入れるかどうかを決定。</li>
<li>入ると同時にフラグを下げる</li>
<li>以上の２つの処理自体が分割できない操作である。</li>
</ul>
<h2 id="dekkerのアルゴリズム">Dekkerのアルゴリズム</h2>
<p>２プロセスの排他制御を行うことを可能する。</p>
<p><strong>Interest</strong>：</p>
<ul>
<li>プロセスA，Bがクリティカルセクションに興味があるか否かを示す。</li>
<li>まずクリティカルセクションに入る前に，クリティセクションに入りたい皆を宣言。競合者がいなければ入れる。</li>
</ul>
<p><strong>Priorityt</strong>：</p>
<ul>
<li>プロセスA，Bがクリティカルセクションに同時に興味を持った場合，どちらを優先するかを決定する。</li>
<li>自分に優先度が回ってくるまでInterest状態を解除。</li>
</ul>
<p>ポイント：</p>
<ul>
<li>入る前に手を挙げる。</li>
<li>優先権により競合を解決。</li>
</ul>
<p><strong>問題点</strong>：</p>
<ul>
<li>ユーザプログラムに依存
<ul>
<li>ちゃんとプロセスが約束を守ってくれないと破綻。</li>
</ul>
</li>
<li><strong>ビジーウェイト（busy　wait）</strong>
<ul>
<li>一方がクリティカルセクションを実行中，待っている方は優先権をひたすらチェックし続ける-&gt;CPUリソースの無駄。</li>
</ul>
</li>
<li>最近はメニューコアが主流。CPUリソースが余っているためビジーウェイトが必ずしも悪ではない状況が発生
<ul>
<li><strong>ビジーウェイトの利点</strong>
<ul>
<li><strong>リソースが空いた時の反応が早い</strong></li>
<li>スピンロック</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="割り込み制御による排他制御">割り込み制御による排他制御</h2>
<p>単一プロセッサシステムの場合，</p>
<ul>
<li>割り込みのみがプロセス中断を発生させる
<ul>
<li>エントリシーケンスで，割り込み禁止命令を実行しておけば良い</li>
<li>同様にイグジットシーケンスで割り込み禁止を解除</li>
</ul>
</li>
<li>ただし
<ul>
<li>割り込み禁止時間の増加はシステムの性能に影響</li>
<li>OS実行の自由度が少なくなり，応答時間が増加。</li>
<li>長時間割り込みが禁止された場合，入出力要求への対応ができなくなり，OSが停止する可能性がある。</li>
</ul>
</li>
</ul>
<h2 id="ハードウェアによる排他制御">ハードウェアによる排他制御</h2>
<p>対話処理の重要性から排他制御の必要性が認識される</p>
<p><strong>テストアンドセット命令</strong>：</p>
<ul>
<li>ハードウェア自体に，排他制御のための仕組みを</li>
<li>v = test_and_set(x)
<ul>
<li>v = x と x = 0を同時に実行する命令</li>
</ul>
</li>
<li>競合者フラグのチェックとセットを同時に行える。</li>
<li><strong>２つの変数に同時に作用することにより，非常に少ないソフトウェアの実行コストでの排他制御が実現可能になった。</strong></li>
</ul>
<hr>
<p>1.複数のプロセスを同時に実行する環境においては，<strong>プロセス競合</strong>，<strong>プロセス協調</strong>が重要となる。これらの解決には，プロセス間の同期手法が基本となる。</p>
<p>2.プログラムが中断されることにより，プロセス競合が起こる可能性のあるプログラム領域を<strong>クリティカルセクション</strong>と呼ぶ。クリティカルセクション実行中は，他のプロセスが同時にクリティカルセクションに入らないように**排他制御(MUTEX)**を行う必要がある。</p>
<p>3.ソフトウェアによる排他制御の基本的な手法として，Dekkerのアルゴリズムがある。しかし，このアルゴリズムの問題点としては<strong>ビジーウェイテイング</strong>がある。</p>
<p>4.クリティカルセクションの前後で割り込みを禁止することによる排他制御の実現手法は，システムの性能に影響を及ぼす場合が多いので，できる限り利用は避けるべきである。</p>
<p>5.排他制御を実現するためのハードウェア支援として**テストアンドセット（TS）**命令が開発され，現在でも排他制御のための基本命令である。</p>
<p>4.1 排他制御を行う手法として，割り込み禁止命令を用いる方法がある。この方法の利点と欠点を挙げよ。<br>
　利点：プログラミングが容易である。欠点：長時間の割り込み禁止はシステム性能の低下につながる。</p>
<p>4.2 排他制御を実現するための命令追加について，TS命令がSWAP命令に比べて容易に実現できることを示せ。<br>
　SWAP命令は，２つのレジスタを交換するため。以下のような命令操作が必要となる。<br>
TEMP    &lt;-  R1<br>
R1      &lt;-  R2<br>
R2      &lt;-  R1<br>
　これは。CPU内で3回のデータ転送が必要であることを示している。現在はデータ転送を1回とするRISCアーキテクチャが主流のため，容易に実装することは困難であり，3回のデータ転送を1命令で行う専用回路が必要となる。<br>
　一方，TS命令の命令操作は以下である。<br>
R2 &lt;-   R1<br>
R1 &lt;-   &quot;0&quot;<br>
　１行目は通常のレジスタ転送であり，CPUのハードウェア拡張は必要としない。さらに，0をレジスタに代入するのはGNDレベルを用いて代入操作ができるため，データ転送のための特別な回路も必要としない。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[OS：CPUの仮想化ースケジューリング]]></title>
        <id>https://zy080080.github.io/post/RWPOSZYfW/</id>
        <link href="https://zy080080.github.io/post/RWPOSZYfW/">
        </link>
        <updated>2021-01-14T06:48:50.000Z</updated>
        <summary type="html"><![CDATA[<p>教科書第3章　まとめ</p>
]]></summary>
        <content type="html"><![CDATA[<p>教科書第3章　まとめ</p>
<!-- more -->
<h2 id="プロセス中断方式">プロセス中断方式</h2>
<p><strong>プリエンプション方式</strong>：OSが実行中のプロセスの実行権を強制的に取り上げることにより，プロセスを中断させる方式。（Windows　XP以降，UNIX，Mac OSなど）</p>
<p><strong>ノンプリエンプション方式</strong>：OSではなく，実行中のプロセスが自主的にCPUリソースをOSに戻す方式。この方式によるマルチタスク（マルチプログラミング）の実装は容易であるが，もしプログラムの暴走により，自発的なCPUリソースの返還がない場合は，<strong>システムの停止に繋がる</strong>。</p>
<h2 id="スケジューリングの目的">スケジューリングの目的</h2>
<p>リソースを効率的に利用するために，効率の良いスケジューリングが必要。</p>
<p>スケジューリングアルゴリズムの効率化の指標：</p>
<ul>
<li><strong>応答時間</strong>
<ul>
<li>その定義は，対象処理がバッチ処理か対話処理かどうかで異なる。
<ul>
<li>バッチ処理の場合，ジョブが投入してから結果を受け取るまでの時間と定義され，<strong>ターンアラウンドタイム</strong>とも呼ばれる。</li>
<li>対話処理の場合，端末から命令を入力した後に，コンピュータシステムから結果を受け取るまでの時間と定義され，<strong>レスポンスタイム</strong>とも呼ばれる。</li>
</ul>
</li>
</ul>
</li>
<li><strong>スループット</strong>
<ul>
<li>単位時間に行われるユーザに有益な仕事量。ただし，プロセスを切り替えるときのオーバーヘッドなど，ユーザの仕事に直接関係しない仕事は仕事量に含まれない。</li>
</ul>
</li>
</ul>
<p>応答時間とスループットは相反することもある。例えば，レスポンスタイムを向上させるためには，対話処理を実行するプロセスに，非常に短い間隔でCPUリソースを与えるようなスケジューリングアルゴリズムが有効である。しかし，このようにクオンタムの非常に小さいスケジューリング手をスループットの面から見た場合，頻繁なプロセス切り替え操作はオーバーヘッドの増加に繋がる。<br>
一方，スループットを向上させるためには，入出力操作やコンテキスト切り替えなど，オーバーヘッドの対象となるような操作をできる限り排除し，計算処理そのものにCPUリソースを用いることが有効となる。</p>
<p><strong>応答時間向上を追求-&gt;対話型処理を優先的に-&gt;TSSクオンタムを短く-&gt;切り替え回数増加，切り替えオーバーヘッド増加-&gt;スループット低下</strong></p>
<h2 id="様々なスケジューリング方式">様々なスケジューリング方式</h2>
<p><strong>FIFO(First In First Out)到着順スケジューリング，FCFS(First Come First Served)</strong>：</p>
<ul>
<li>特徴：
<ul>
<li>単純：プロセス選択機構も簡単になるし，選択オーバーヘッドも小さい</li>
<li>公平：追い抜き禁止</li>
</ul>
</li>
<li>欠点：ターンアラウンドタイムはよくない
<ul>
<li>待ち行列が100s,1s,1s,1sの時平均待ち時間27s</li>
<li>待ち行列が1s,1s,1s,100sの時平均待ち時間102s</li>
</ul>
</li>
</ul>
<p><strong>SPTF(Shortest Processing Time First)処理時間順スケジューリング</strong>：</p>
<ul>
<li>待ち行列内プロセスを処理時間順でソート</li>
<li>特徴：応答時間最短，理想的</li>
<li>欠点：実装不可能，各プロセスの処理時間を事前に知ることができない。
<ul>
<li>経験則（heuristic）から近似的に処理時間を求める。</li>
<li>近似実装：すでに実行した時間から。入出力処理から。</li>
</ul>
</li>
<li>亜種：残り処理時間順（SRTF）</li>
</ul>
<p><strong>PS(Priority Scheduling)優先度順スケジューリング</strong>：</p>
<ul>
<li>各プロセスに優先度を付加
<ul>
<li><strong>静的優先度</strong>：プロセス生成時に指定した優先度を使用。
<ul>
<li>例：プロセスの種類ごとに優先度を規定。リアルタイムプロセス&gt;OS&gt;対話型&gt;バッチ</li>
</ul>
</li>
<li><strong>動的優先度</strong>：プロセス実行中に優先度を適宜変化
<ul>
<li>例：既実行時間に応じて優先度を変化。入出力操作直後のプロセスの優先度を高く。</li>
</ul>
</li>
</ul>
</li>
<li>利点：優先度を適切に設定できれば非常に有効。</li>
<li>欠点：高負荷時，優先度の低いプロセスがなかなか実行権を獲得できない（starvation）-&gt;<strong>待ち時間に応じた優先度変化(agingエージング)などで対処</strong>。</li>
</ul>
<p><strong>RR(Round Robin)ラウンドロビン</strong>：</p>
<ul>
<li>TSSで用いられる方式。</li>
<li>待ち行列から選択されたプロセスに，微小なCPU利用時間（クオンタム）を割り当て。</li>
<li>クオンタム-&gt;無限大：RR＝FIFO</li>
<li>クオンタム＝極小：処理時間の短いプロセスに有利</li>
</ul>
<p><strong>MLF(Muti-Level Feedback)多重レベルフィードバック</strong>：</p>
<ul>
<li>Multi-Level Feedback (from Multics Project)
<ul>
<li>優先度別に待ち行列を用意。</li>
<li>プロセスは，クオンタムを得るごとにより優先度の低い待ち行列に移される。</li>
</ul>
</li>
<li>Multi-Level Feedback
<ul>
<li>複数のクオンタムを必要とするようなプロセス（すなわち長い時間がかかるプロセス）は，どんどん優先度が下がってゆく。</li>
<li>SPTFの良い近侍になっている。</li>
</ul>
</li>
</ul>
<hr>
<p>1.CPUスケジューリングには，<strong>到着順スケユーリング</strong>，<strong>処理時間順スケジューリング</strong>，<strong>優先度順スケジューリング</strong>，<strong>ラウンドロビン(Round-Robin)スケジューリング</strong>，<strong>多重レベルフィードバックスケジューリング</strong>などの方式があり，OSが用いられる環境によって様々なスケジューリングが適用されている。スケジューリング自体，１秒間に数十から数百回行う処理であり，スケジューリングの効率とともに，高速性も同時に要求される。</p>
<p>2.<strong>処理時間順スケジューリング</strong>は，理論上応答時間を最小にすることが知られている。しかし，プロセスの処理時間を，実行前に知ることは不可能である。そこで，既実行時間の少ないプロセスは，処理時間も少ないという経験的な法則を用い，近似的な処理時間順スケジューリングが用いられる。</p>
<p>3.優先度には，プロセスの生成時に決まる<strong>静的優先度</strong>と，実行中に変化する<strong>動的優先度</strong>がある。通常の対話処理では，この２つの優先度を用いてスケジューリングする場合が多い。優先度スケジューリング時には，スタベーションの問題を解決するためにエージングが併用されることが多い。</p>
<p>3.1 次の文の括弧を埋めよ（下線部の後では下線部の意味に対応する言葉を書くこと）<br>
　プロセスのスケジューリング手法の一例として，残り処理時間順(SPT)スケジューリングがある。これは処理時間の短いプロセスから順に実行する方式であり，理論上は応答時間を最小にすることができる。この方式ではあるプロセスが実行中でも，より処理時間の短いプロセスが入ってきた場合には，（実行中のプロセスはオペレーティングシステムにより中断）（<strong>プリエンプション</strong>）される。<br>
　優先度スケジューリングにおいては，優先度の低いプロセスになかなか実行権が回ってこない場合がある。この現象を（スタベーションstarvation）と呼び，通常（<strong>エージング</strong>）を併用することより回避する。</p>
<p>3.2 リアルタイム処理に用いられるデッドラインスケジューリングについて調べよ。<br>
　プロセスの実行に終了目標時間（deadline）を設定し，目標時間に近づくと，プロセスの優先度を上げて該当プロセスにCPUリソースが配分されやすいようにするスケジューリング。この方式だけでは処理のリアルタイム性を厳密に保証することは困難であるが，近似的な実装手法としてよく用いられる。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[OS：CPUの仮想化ープロセス]]></title>
        <id>https://zy080080.github.io/post/OENVD2_g7/</id>
        <link href="https://zy080080.github.io/post/OENVD2_g7/">
        </link>
        <updated>2021-01-14T00:09:26.000Z</updated>
        <summary type="html"><![CDATA[<p>教科書第二章まとめ</p>
]]></summary>
        <content type="html"><![CDATA[<p>教科書第二章まとめ</p>
<!-- more -->
<p></p>
<p>プロセス：ユーザの代わりにOSに対してリソースを要求するとともに，リソースの割り当てを受ける単位。システムが処理する仕事の単位。</p>
<p>プロセス処理形態</p>
<ul>
<li>ユニプロセッサ・ユニプログラミング方式
<ul>
<li>１つのCPUに対して１つのプロセス</li>
<li>バッチ処理</li>
</ul>
</li>
<li>ユニプロセッサ・マルチプログラミング方式
<ul>
<li>１つのCPUに対して複数のプロセス</li>
<li>TSS（Time　Sharing　System　時分割処理方式）</li>
</ul>
</li>
<li>マルチプロセッサ・マルチプログラミング方式
<ul>
<li>複数のCPUに対して複数のプロセス</li>
<li>並列・分散処理</li>
</ul>
</li>
</ul>
<p><strong>同時実行できるプロセス数よりCPUが多いとCPUが遊んでいてもったいないため，プロセスをさらに小さい単位に分割。</strong></p>
<p><strong>スレッド</strong>：CPUリソースが割り当てられる論理単位。</p>
<ul>
<li>CPUリソースをスレッドごとに割り当て</li>
<li>プログラムの実行においては，スレッドは１つの命令の流れとしてとらえることができる。</li>
<li>利点
<ul>
<li>TSSによる切り替えオーバヘッドが軽い
<ul>
<li>同一プロセスから生成されてるから<strong>メモリ領域が同じ</strong>。</li>
<li>メモリ使用量は<strong>1プロセス分</strong>で済む。</li>
<li><strong>別名：Light Weight Process</strong></li>
<li>マルチスレッドの場合，各スレッドは，独自にレジスタ群とスタックを持つともに，CPUリソースのwリアて単位となる。その他，プロセス内で管理される主記憶，プログラム領域，静的変数領域，動的変数領域，PSWなどが，各スレッド間で共有される。また，ファイル情報をプロセス単位で管理されるため，スレッドの生成が軽量（早い）である。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>プロセスとスレッドの違い：</p>
<ul>
<li>プロセス
<ul>
<li>Microsoft Word</li>
<li>Microsoft Excel</li>
<li>各プログラムはプロセスとして処理</li>
</ul>
</li>
<li>スレッド
<ul>
<li>Wordの場合，印刷，編集など，同じ『Word』というプログラムの中で<strong>同時（並行）動作できる単位</strong>                                                                                           |<br>
<strong>イベント</strong>：CPU内での通常の計算処理以外の事象。</li>
</ul>
</li>
</ul>
<p><strong>インターバルタイマー</strong>：TSSで用いる一定時間ごとに決まったイベントを発生させるための装置。</p>
<ul>
<li>TSSでは，定期的な切り替えが必要。インターバルライマが定期的に割込みを発生することで切り替えを実現する。</li>
</ul>
<p><strong>割込み</strong>：通常のCPU演算動作とは異なる事象のこと。</p>
<ul>
<li>キーボード入力を受け取ったなど</li>
<li>割込み発生時にプロセスの切り替えが起こる。</li>
</ul>
<p><strong>割込み処理</strong>：割り込みが発生した時に，CPUには非常に高速かつ軽量に処理するプログラムを実行可能なプログラム実行方式。</p>
<ul>
<li>内部割り込み
<ul>
<li>スーパバイザコール割込み</li>
<li>プログラムチェック（例外）割込み</li>
<li>実行中のプログラムを発生原因とする</li>
<li>プログラム自体の異常など</li>
</ul>
</li>
<li>外部割り込み
<ul>
<li>入出力割込み</li>
<li>タイマ割込み</li>
<li>マシンチェック割込み（冷却装置の異常，電源装置の異常など）</li>
<li>リスタート割込み</li>
<li>その他の要因で発生する</li>
<li>ほかの優先的処理からの要求，ハードウェア異常など</li>
</ul>
</li>
</ul>
<p><strong>スーパバイザモード</strong>：OSを実行するモードであり，CPUが有する全ての命令とOSが管理する全てのリソース扱うことが可能。</p>
<p><strong>ユーザモード</strong>：ユーザの作成した応用プログラムを実行するモードであり，実行できる命令や利用できるリソースに制限がある。</p>
<p><strong>スーパバイザコール割込み</strong>：ユーザプログラムがOSに対して処理を依頼する際に発生する割込み。</p>
<ul>
<li>この時にCPUの実行モードが切り替わる</li>
</ul>
<p><strong>例外割込み（プログラムチェック割込み）</strong>：実行中のプログラムで以上が起こった時に発生する割込み。</p>
<p><strong>割込み処理ルーチン</strong>：割込みハンドラ，割込み処理プログラム。</p>
<p><strong>PSW(Program Status Word)プログラム状態語</strong>：CPU内のプロセスの再開必要なレジスト情報。</p>
<ul>
<li>プログラムカウンタの値</li>
<li>スタックレジスタの値</li>
<li>汎用レジスタの値</li>
<li>割込みマスク（割り込みを禁止すること）の値など</li>
</ul>
<p><strong>PCB(Process Control Block)プロセス制御ブロック</strong>：メモリ上の，PSWを待避するための領域。</p>
<ul>
<li>プロセス識別子　各プロセスに割当てられる一連の番号</li>
<li>PSW　中断時に伝送されたPSW情報</li>
<li>ユーザ名　プロセスの所有者</li>
<li>実行優先度　プロセスに与えられている実行優先度</li>
<li>既実行時間　プロセスがすでにCPUリソースを消費した時間。実行優先度とともに，スケジューリングに用いる。</li>
<li>リソース情報　プロセスの確保しているリソース情報</li>
</ul>
<p><strong>割込みベクタ</strong>：割込みの種類に対応する数字（ID）<br>
割込み処理ルーチン内では，割込みの種類を解析し，その割込みの種類に応じた処理ルーチンを実行する</p>
<p><strong>割込みベクタテーブル</strong>：割込み処理ルーチンは，あらかじめ処理の内容に応じて，実行する処理の番地をテーブル化したもの。<strong>処理の高速化を図る</strong>。<br>
割込み処理ルーチンはメインメモリ上にある割込みベクタテーブルと，システムバス上の割込みベクタ番号から，次に実行するアドレスを迅速に決定する。</p>
<p><strong>実行状態（running）</strong>：プロセスを実行している状態。リソースは，そのプロセスのために確保されている。</p>
<p><strong>実行可能状態（ready）</strong>：実行できるが，CPUリソースが確保できていない状態。CPUリソースを確保した時点で実行開始される。</p>
<p><strong>待ち状態（waiting）</strong>：CPU以外のリソースも確保できていない状態。入力待ちなどもこれに含まれる。</p>
<hr>
<p>1.プロセスの中断，再開は，<strong>割り込み</strong>により行う。割り込みが発生した場合，オペレーティングシステムは，<strong>割込み処理ルーチン</strong>にただちに処理を切り替える。割込み処理ルーチン内で，まず実行中のPSWを主記憶内に伝送し，次にCPUスケジューラを起動させ，そして実行するプロセスを選ぶ。最後に，実行するプロセスのPSWをCPU内に伝送することにより，新しいプロセスを再開する。これら一連の処理を<strong>コンテキスト切り替え</strong>と呼ぶ。</p>
<p>2.OS内におけるプロセスは，全ての実行に必要なリソースを獲得して実行中の<strong>実行状態</strong>(Running)，CPU以外のリソースは全て獲得CPUリソースさえ獲得できれば<strong>実行可能状態</strong>(ready)，CPU以外のリソースの不足，もしくは他のプロセスからのデータ待ちの<strong>待ち状態</strong>(wait)，の３つの状態で存在する。</p>
<p>2.1<br>
　OS内におけるプロセスの状態は，（実行状態），（実行可能状態），（待ち状態）の３つの状態に分けることができる。（実行状態）から（実行可能状態）への状態遷移は優先度の高いプロセスの割込みや，CPUスケジューラにより割り当てられたCPU時間（クオンタム）を使った時に起こる。<br>
　プロセスの実行情報は，主にレジスタ情報が（PSW）に，それ以外の実行時間やプロセス名などの情報が（PCB）に格納されている。実行中のプロセスが中断された場合，これらの情報を保存しなければならない。この一連の操作を（コンテキスト）切り替えと呼び，最近のCPUには（PSW）を高速に保存する仕組みがある。</p>
<p>2.2 割込み時に，割込みの種類をベクタとして，割込み処理ルーチンに渡すのはなぜか，また，ベクタとして渡す以外の他の方法についても考査せよ。<br>
　割込みは，頻繁にかつ様々な原因で発生するため，その処理はできる限り高速に行わなければならない。割込みベクタを用いることで，OSは制御がどのアドレスに移されたかにより，割込みの原因を高速かつ容易に知ることができる。<br>
　また，割込みベクタを用いない方法として，状態（cause）レジスタを用いる方法がある。この場合，割り込みが発生した時点で，同一の割込み処理ルーチンに制御が移り，割込み処理ルーチン内で，状態レジスタを参照することにより，適切な割込み処理を行う。</p>
<p>2.3 OSを理解する上で，速度オーダーの理解は重要である。本書が想定する以下の速度を答えよ</p>
<ul>
<li>CPUの１命令実行   10^(-9)</li>
<li>主記憶からCPUに内容を伝送する速度 10^(-7)</li>
<li>2時記憶の読み出し（書き込み速度） 10^(-3)</li>
<li>人の反応速度  10^(-1)</li>
</ul>
<p>2.4 PCBの場合はA，PSWの場合はB，どちらにも含まれない場合はC<br>
プロセス識別子（A）  ユーザ名（A）    既実行時間（A）  実行優先度（A）  プログラムカウンタ（B）<br>
割込みマスク（B）    割込みベクタテーブル（C）    割込み処理ルーチン（C）</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[OS：OSとは]]></title>
        <id>https://zy080080.github.io/post/mq2xVP1Fs/</id>
        <link href="https://zy080080.github.io/post/mq2xVP1Fs/">
        </link>
        <updated>2021-01-11T11:25:54.000Z</updated>
        <summary type="html"><![CDATA[<p>教科書第1章　要点まとめ</p>
]]></summary>
        <content type="html"><![CDATA[<p>教科書第1章　要点まとめ</p>
<!-- more -->
<p>オペレーティングシステムは，ハードウェアの確保，ユーザインタフェース，入出力制御など，プログラム本体とは異なる制御を，プログラマが意識することなく，プログラムすることを可能とする一連の制御プログラムの集合体なのである。</p>
<p><strong>仮想化</strong>：オペレーティングシステムは『ハードウェアへのアクセスの容易性』，『ハードウェアリソースの確保の確認に対する容易性』を確保するために，有限個しかないハードウェアリソースを無限個，無限大のハードウェアリソースとしてプログラム側に提供すること。</p>
<p><strong>多重化</strong>：ハードウェアリソース数を，実際の数より多く見せる操作。</p>
<ul>
<li><strong>時分割多重化</strong>：時間軸上での多重化。時間を区切ることにより，ハードウェアリソースを複数のプログラムに交互に利用させる方式である。</li>
<li><strong>空間分割多重化</strong>：空間軸上での多重化。ハードウェアリソースを複数の領域に区切ることにより，複数のプログラムに別々の領域を利用させる方式である。</li>
</ul>
<p><strong>バッチ処理</strong>：ユーザがジョブをコンピュータに一括して依頼し，コンピュータはプログラムの実行前に一括に投入されたジョブに含まれる情報のみによって処理を行う方式。</p>
<ul>
<li>具体的には，実行時に必要とするリソース（CPU時間，メモリ量など），プログラム本体（ソースコード），データ（入力データ）が投入される。</li>
<li>特徴：実行上必要なリソースを全て実行前に宣言すること。</li>
<li>利点：
<ul>
<li>スケジューリングが単純。
<ul>
<li>前もってプログラムが必要とするリソースが分かる。</li>
<li>複数のジョブのスケジューリングが楽（必要リソースの少ないジョブを優先的に実行すると，全ジョブの平均待ち時間が短くなる）。</li>
<li>ジョブの切り替えも少なくてすむため，無駄が少ない。</li>
</ul>
</li>
</ul>
</li>
<li>欠点：
<ul>
<li>前もって全てを決めないとジョブが投入できない。Ï</li>
</ul>
</li>
</ul>
<p><strong>対話処理</strong>：プログラムの実行中に入力が必要となった場合に，ユーザがその時点で入力を行い，プログラムの実行を制御する処理形態。</p>
<ul>
<li>対話処理を採用する場合の代表的なプロセス実行形態として<strong>タイムシェアリングシステム（時分割処理方式　time sharing sysytem:TSS）</strong></li>
</ul>
<p><strong>クオンタム</strong>：一回に割当てられる時間。</p>
<p><strong>TSS（Time Sharing System 時分割処理方式）</strong>：複数のプロセスに非常に短い時間（10^(-3)秒程度）単位でCPUの実行権を与え，対話処理を実行中の各プロセスにあたかもCPUを占有しているかのように見せかけるCPUの時間軸方向の仮想化手法。(人的反应慢，反应不过来被分配给其他处理的时间，从人的视角来看好像只在处理一个process而已)</p>
<ul>
<li>使っていないCPU時間を他に割り当てる。割り当てられる単位時間（クオンタム）は数10ms。</li>
<li>利点：
<ul>
<li>自分の他に大きなプロセスがあっても，そのプロセスが終わるまで長い時間待たされたりしない。（バッチ処理ではありうる）。各プロセスの待ち時間は短い。</li>
<li>ユーザから見ても，対話的に入力してからその反応が返ってくるまでの時間（レスポンスタイム）が短くなる。</li>
</ul>
</li>
</ul>
<p><strong>リアルタイム処理</strong>：あるジョブやプロセスが発生した時点から決めた時間内に実行を保証する処理。</p>
<p><strong>分散処理</strong>：複数のコンピュータを同時に用いて一連の処理を行う方式。</p>
<hr>
<p>1.<strong>オペレーティングシステム</strong>の目的は，ハードウェアリソース，ソフトウェアリソースの利用時における容易性，効率性の向上である。<br>
2.リソースを配分される単位を<strong>プロセス</strong>と呼び，ユーザから見たコンピュータに依頼する仕事のまとまりを<strong>ジョブ</strong>と呼ぶ。<br>
3.オペレーティングシステムの基本的な枠組みは，リソースの<strong>仮想化</strong>と仮想化されたリソースの<strong>スケジューリング</strong>にある。<br>
4.プログラムの処理形態は，<strong>バッチ処理</strong>と<strong>対話処理</strong>の２つが基本である。他にも，リアルタイム処理や分散処理などオペレーティングシステムの処理形態は広がりつつある。<br>
5.効率化の指標は大きく分けて，プログラムの実行を依頼してから結果が帰ってくるまでの時間の尺度である<strong>レスポンズタイム</strong>（対話処理の場合），<strong>ターンアラウンドタイム</strong>(バッチ処理の場合)と，一定時間内にコンピュータシステムが行う仕事量の尺度である<strong>スループット</strong>がある。</p>
<p>1.1 プロセスとジョブの違いについて説明せよ。<br>
　プロセスは，オペレーティングシステム側から見たリソースの割り当て対象であり，ジョブとは，ユーザ側から見たオペレーティングシステムに対して処理を依頼する，ひとまとまりの仕事を表す。したがって，１つのジョブは通常１つ以上のプロセスから構成される。なお，ジョブという言葉は，バッチシステムでは一般的であり，TSSを基本とするオペレーティングシステムではあまり用いられない。</p>
<p>1.2 空間分割によるリソースの多重化時に考えられるオーバーヘッドについて説明せよ。<br>
　空間分割による多重化を行うためには，プロセスの必要とするリソースがどのような位置に配置されても，プロセス側からは同様のアドレスを指定することにより，アクセスの可能である設計が必要となる。したがって，オペレーティングシステムでは，プロセス側で指定するリソースの位置と実際の物理的なリソースの位置との間の変換を行う作業が必要となる。</p>
<p>1.3 個人が使用するオペレーティングシスレムにおいてもTSSが一般的に用いられている。この理由を，ユーザからみた利便性，システム資源の有効利用の面から考察せよ。<br>
　ユーザからみた利便性：個人が使用するオペレーティングシステムにおいても，複数の仕事を同時に実行することが必要である。ネットワーク入出力，華やかなグラフィカルユーザインターフェース，個人のスケジュール管理ソフトなどなど縁の下の力持ち的なソフトウェアの増加など，ユーザの利便性を追求することを目的とするプロセスは増大の一方である。したがって，複数のプロセスを同時に実行可能なTSS環境は必須である。<br>
　システム資源の有効利用：個人が使用するオペレーティングシステムで実行されているプロセスの大部分は，CPUリソースをほとんど消費しない待ちの状態が多い（ゲームなどCPUリソースを大量に使うアプリケーションの実行時は除く）。例えば，スケジュール管理ソフトは決められた時刻が来た時，もしくはユーザのスケジュール入力時のみ動作すれば良い。したがって，TSSによるCPUリソースの多重化を行っても見かけ上のプログラム実行速度の変化がないだけでなく，待ち時間の有効利用はシステム資源の有効利用となる。</p>
<p>1.4 時分割多重化の利点と欠点<br>
　時分割多重化の利点には，時間を区切ることにより，ハードウェアリソースを複数のプログラムに交互に利用させることができ，CPUなど空間分割が不可能な時に利用できることがある。ただし，欠点として，使用者が切り替わる時に無駄（オーバヘッド）が発生する。電子機械では，短い時間で切り替えるため，切り替え回数が増加すると，オーバヘッドも増加してしまう。</p>
<p>数値の重要性</p>
<ul>
<li>
<p>計算機の基本周期（クロック）は？</p>
<ul>
<li>１単位の処理時間10<sup>(-9)秒(1ns)，クロックだと10</sup>9回(1GHz)</li>
</ul>
</li>
<li>
<p>主記憶へのアクセス遅延は？</p>
<ul>
<li>10^(-7)秒(100ns)</li>
</ul>
</li>
<li>
<p>2次記憶へのアクセス遅延は？</p>
<ul>
<li>10^(-2)秒(5ms~10ms)</li>
</ul>
</li>
<li>
<p>人間のキーボード入力速度は？</p>
<ul>
<li>10^(-1)秒</li>
</ul>
</li>
</ul>
]]></content>
    </entry>
</feed>